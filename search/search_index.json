{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PyTabular What is it? PyTabular (python-tabular in pypi ) is a python package that allows for programmatic execution on your tabular models! This is possible thanks to Pythonnet and Microsoft's .Net APIs on Azure Analysis Services . The package should have the dll files included when you import it. See Documentation Here . PyTabular is still considered alpha while I'm working on building out the proper tests and testing environments, so I can ensure some kind of stability in features. Please send bugs my way! Preferably in the issues section in Github. I want to harden this project so many can use it easily. I currently have local pytest for python 3.6 to 3.10 and run those tests through a local AAS and Gen2 model. Getting Started See the Pypi project for available version. python3 -m pip install python-tabular In your python environment, import pytabular and call the main Tabular Class. Only parameter needed is a solid connection string. import pytabular model = pytabular.Tabular(CONNECTION_STR) You can query your models with the Query method from your tabular class. For Dax Queries, it will need the full Dax syntax. See EVALUATE example . This will return a Pandas DataFrame . If you are looking to return a single value, see below. Simply wrap your query in the the curly brackets. The method will take that single cell table and just return the individual value. You can also query your DMV. See below for example. See PyTabular Docs for Query . #Run basic queries DAX_QUERY = \"EVALUATE TOPN(100, 'Table1')\" model.Query(DAX_QUERY) #returns pd.DataFrame() #or... DMV_QUERY = \"select * from $SYSTEM.DISCOVER_TRACE_EVENT_CATEGORIES\" model.Query(DMV_QUERY) #returns pd.DataFrame() #or... SINGLE_VALUE_QUERY_EX = \"EVALUATE {1}\" model.Query(SINGLE_VALUE_QUERY_EX) #returns 1 #or... FILE_PATH = 'C:\\\\FILEPATHEXAMPLE\\\\file.dax' #or file.txt model.Query(FILE_PATH) #Will return same logic as above, single values if possible else will return pd.DataFrame() Refresh method to handle refreshes on your model. This is synchronous. Should be flexible enough to handle a variety of inputs. See PyTabular Docs for Refreshing Tables and Partitions . Most basic way to refresh is input the table name string. The method will search for table and output exeption if unable to find it. For partitions you will need a key, value combination. Example, {'Table1':'Partition1'}. You can also take the key value pair and iterate through a group of partitions. Example, {'Table1':['Partition1','Partition2']}. Rather than providing a string, you can also input the actual class. See below for those examples, and you can acess them from the built in attributes self.Tables, self.Partitions or explore through the .Net classes yourself in self.Model.Tables. #You have a few options when refreshing. model.Refresh('Table Name') #or... model.Refresh(['Table1','Table2','Table3']) #or... model.Refresh(<Table Class>) #or... model.Refresh(<Partition Class>) #or... model.Refresh({'Table Name':'Partition Name'}) #or any kind of weird combination like model.Refresh([{<Table Class>:<Partition Class>,'Table Name':['Partition1','Partition2']},'Table Name','Table Name2']) #Add Tracing=True for simple Traces tracking the refresh. model.Refresh(['Table1','Table2'], Tracing=True) Use Cases If blank table, then refresh table. This will use the function Return_Zero_Row_Tables and the method Refresh from the Tabular class. import pytabular model = pytabular.Tabular(CONNECTION_STR) tables = pytabular.Return_Zero_Row_Tables() if len(tables) > 0: model.Refresh(tables, Tracing = True) #Add a trace in there for some fun. Sneak in a refresh. This will use the method Is_Process and the method Refresh from the Tabular class. It will check the DMV to see if any jobs are currently running classified as processing. import pytabular model = pytabular.Tabular(CONNECTION_STR) if model.Is_Process(): #do what you want if there is a refresh happening else: model.Refresh(TABLES_OR_PARTITIONS_TO_REFRESH) Show refresh times in model. This will use the function Table_Last_Refresh_Times and the method Create_Table from the Tabular class. It will search through the model for all tables and partitions and pull the 'RefreshedTime' property from it. It will return results into a pandas dataframe, which will then be converted into an M expression used for a new table. import pytabular model = pytabular.Tabular(CONNECTION_STR) df = pytabular.Table_Last_Refresh_Times(model, group_partition = False) model.Create_Table(df, 'Refresh Times') If BPA Violation, then revert deployment. Uses a few things. First the BPA Class , then the TE2 Class , and will finish with the Analyze_BPA method. Did not want to re-invent the wheel with the amazing work done with Tabular Editor and it's BPA capabilities. import pytabular model = pytabular.Tabular(CONNECTION_STR) TE2 = pytabular.TE2() #Feel free to input your TE2 File path or this will download for you. BPA = pytabular.BPA() #Fee free to input your own BPA file or this will download for you from: https://raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json results = model.Analyze_BPA(TE2.EXE,BPA.Location) if len(results) > 0: #Revert deployment here! Backup & Revert a Table. USE WITH CAUTION, obviously not in PROD. I have been experimenting with this concept. Made for selfish reasons. Will probably get removed and I'll keep in my own local version. But fun to work with. Uses two methods. Backup_Table and Revert_Table import pytabular model = pytabular.Tabular(CONNECTION_STR) model.Backup_Table('TableName') #This will backup the table with surround items (columns,measures,relationships,roles,hierarchies,etc.) and will add a suffix of '_backup' #-----------# #Make any changes to your original table and then revert or delete backup as necessary #-----------# model.Revert_Table('TableName') #This will essentially replace your original with _backup Loop through and query Dax files Let's say you have multiple dax queries you would like to store and run through as checks. The Query method on the Tabular class can also take file paths. Can really be any file type as it's just checking os.path.isfile(). But would suggest .dax or .txt. It will read the file that use that as the new Query_str argument. import pytabular model = pytabular.Tabular(CONNECTION_STR) LIST_OF_FILE_PATHS = ['C:\\\\FilePath\\\\file1.dax','C:\\\\FilePath\\\\file1.txt','C:\\\\FilePath\\\\file2.dax','C:\\\\FilePath\\\\file2.txt'] for file_path in LIST_OF_FILE_PATHS: model.Query(file_path) Contributing See CONTRIBUTING.md","title":"Home"},{"location":"#pytabular","text":"","title":"PyTabular"},{"location":"#what-is-it","text":"PyTabular (python-tabular in pypi ) is a python package that allows for programmatic execution on your tabular models! This is possible thanks to Pythonnet and Microsoft's .Net APIs on Azure Analysis Services . The package should have the dll files included when you import it. See Documentation Here . PyTabular is still considered alpha while I'm working on building out the proper tests and testing environments, so I can ensure some kind of stability in features. Please send bugs my way! Preferably in the issues section in Github. I want to harden this project so many can use it easily. I currently have local pytest for python 3.6 to 3.10 and run those tests through a local AAS and Gen2 model.","title":"What is it?"},{"location":"#getting-started","text":"See the Pypi project for available version. python3 -m pip install python-tabular In your python environment, import pytabular and call the main Tabular Class. Only parameter needed is a solid connection string. import pytabular model = pytabular.Tabular(CONNECTION_STR) You can query your models with the Query method from your tabular class. For Dax Queries, it will need the full Dax syntax. See EVALUATE example . This will return a Pandas DataFrame . If you are looking to return a single value, see below. Simply wrap your query in the the curly brackets. The method will take that single cell table and just return the individual value. You can also query your DMV. See below for example. See PyTabular Docs for Query . #Run basic queries DAX_QUERY = \"EVALUATE TOPN(100, 'Table1')\" model.Query(DAX_QUERY) #returns pd.DataFrame() #or... DMV_QUERY = \"select * from $SYSTEM.DISCOVER_TRACE_EVENT_CATEGORIES\" model.Query(DMV_QUERY) #returns pd.DataFrame() #or... SINGLE_VALUE_QUERY_EX = \"EVALUATE {1}\" model.Query(SINGLE_VALUE_QUERY_EX) #returns 1 #or... FILE_PATH = 'C:\\\\FILEPATHEXAMPLE\\\\file.dax' #or file.txt model.Query(FILE_PATH) #Will return same logic as above, single values if possible else will return pd.DataFrame() Refresh method to handle refreshes on your model. This is synchronous. Should be flexible enough to handle a variety of inputs. See PyTabular Docs for Refreshing Tables and Partitions . Most basic way to refresh is input the table name string. The method will search for table and output exeption if unable to find it. For partitions you will need a key, value combination. Example, {'Table1':'Partition1'}. You can also take the key value pair and iterate through a group of partitions. Example, {'Table1':['Partition1','Partition2']}. Rather than providing a string, you can also input the actual class. See below for those examples, and you can acess them from the built in attributes self.Tables, self.Partitions or explore through the .Net classes yourself in self.Model.Tables. #You have a few options when refreshing. model.Refresh('Table Name') #or... model.Refresh(['Table1','Table2','Table3']) #or... model.Refresh(<Table Class>) #or... model.Refresh(<Partition Class>) #or... model.Refresh({'Table Name':'Partition Name'}) #or any kind of weird combination like model.Refresh([{<Table Class>:<Partition Class>,'Table Name':['Partition1','Partition2']},'Table Name','Table Name2']) #Add Tracing=True for simple Traces tracking the refresh. model.Refresh(['Table1','Table2'], Tracing=True)","title":"Getting Started"},{"location":"#use-cases","text":"","title":"Use Cases"},{"location":"#if-blank-table-then-refresh-table","text":"This will use the function Return_Zero_Row_Tables and the method Refresh from the Tabular class. import pytabular model = pytabular.Tabular(CONNECTION_STR) tables = pytabular.Return_Zero_Row_Tables() if len(tables) > 0: model.Refresh(tables, Tracing = True) #Add a trace in there for some fun.","title":"If blank table, then refresh table."},{"location":"#sneak-in-a-refresh","text":"This will use the method Is_Process and the method Refresh from the Tabular class. It will check the DMV to see if any jobs are currently running classified as processing. import pytabular model = pytabular.Tabular(CONNECTION_STR) if model.Is_Process(): #do what you want if there is a refresh happening else: model.Refresh(TABLES_OR_PARTITIONS_TO_REFRESH)","title":"Sneak in a refresh."},{"location":"#show-refresh-times-in-model","text":"This will use the function Table_Last_Refresh_Times and the method Create_Table from the Tabular class. It will search through the model for all tables and partitions and pull the 'RefreshedTime' property from it. It will return results into a pandas dataframe, which will then be converted into an M expression used for a new table. import pytabular model = pytabular.Tabular(CONNECTION_STR) df = pytabular.Table_Last_Refresh_Times(model, group_partition = False) model.Create_Table(df, 'Refresh Times')","title":"Show refresh times in model."},{"location":"#if-bpa-violation-then-revert-deployment","text":"Uses a few things. First the BPA Class , then the TE2 Class , and will finish with the Analyze_BPA method. Did not want to re-invent the wheel with the amazing work done with Tabular Editor and it's BPA capabilities. import pytabular model = pytabular.Tabular(CONNECTION_STR) TE2 = pytabular.TE2() #Feel free to input your TE2 File path or this will download for you. BPA = pytabular.BPA() #Fee free to input your own BPA file or this will download for you from: https://raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json results = model.Analyze_BPA(TE2.EXE,BPA.Location) if len(results) > 0: #Revert deployment here!","title":"If BPA Violation, then revert deployment."},{"location":"#backup-revert-a-table","text":"USE WITH CAUTION, obviously not in PROD. I have been experimenting with this concept. Made for selfish reasons. Will probably get removed and I'll keep in my own local version. But fun to work with. Uses two methods. Backup_Table and Revert_Table import pytabular model = pytabular.Tabular(CONNECTION_STR) model.Backup_Table('TableName') #This will backup the table with surround items (columns,measures,relationships,roles,hierarchies,etc.) and will add a suffix of '_backup' #-----------# #Make any changes to your original table and then revert or delete backup as necessary #-----------# model.Revert_Table('TableName') #This will essentially replace your original with _backup","title":"Backup &amp; Revert a Table."},{"location":"#loop-through-and-query-dax-files","text":"Let's say you have multiple dax queries you would like to store and run through as checks. The Query method on the Tabular class can also take file paths. Can really be any file type as it's just checking os.path.isfile(). But would suggest .dax or .txt. It will read the file that use that as the new Query_str argument. import pytabular model = pytabular.Tabular(CONNECTION_STR) LIST_OF_FILE_PATHS = ['C:\\\\FilePath\\\\file1.dax','C:\\\\FilePath\\\\file1.txt','C:\\\\FilePath\\\\file2.dax','C:\\\\FilePath\\\\file2.txt'] for file_path in LIST_OF_FILE_PATHS: model.Query(file_path)","title":"Loop through and query Dax files"},{"location":"#contributing","text":"See CONTRIBUTING.md","title":"Contributing"},{"location":"Best%20Practice%20Analyzer/","text":"BPA source BPA( File_Path: str = 'Default' ) Setting BPA Class for future work... Download_BPA_File source .Download_BPA_File( Download_Location: str = 'https: //raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json', Folder: str = 'Best_Practice_Analyzer', Auto_Remove = True ) Runs a request.get() to retrieve the json file from web. Will return and store in directory. Will also register the removal of the new directory and file when exiting program. Args Download_Location ( type , optional) : F. Defaults to [Microsoft GitHub BPA]'https://raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json'. Folder (str, optional) : New Folder String. Defaults to 'Best_Practice_Analyzer'. Auto_Remove (bool, optional) : If you wish to Auto Remove when script exits. Defaults to True. Returns str : File Path for the newly downloaded BPA.","title":"Best Practice Analyzer"},{"location":"Best%20Practice%20Analyzer/#_1","text":"","title":""},{"location":"Best%20Practice%20Analyzer/#bpa","text":"source BPA( File_Path: str = 'Default' ) Setting BPA Class for future work...","title":"BPA"},{"location":"Best%20Practice%20Analyzer/#download_bpa_file","text":"source .Download_BPA_File( Download_Location: str = 'https: //raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json', Folder: str = 'Best_Practice_Analyzer', Auto_Remove = True ) Runs a request.get() to retrieve the json file from web. Will return and store in directory. Will also register the removal of the new directory and file when exiting program. Args Download_Location ( type , optional) : F. Defaults to [Microsoft GitHub BPA]'https://raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json'. Folder (str, optional) : New Folder String. Defaults to 'Best_Practice_Analyzer'. Auto_Remove (bool, optional) : If you wish to Auto Remove when script exits. Defaults to True. Returns str : File Path for the newly downloaded BPA.","title":"Download_BPA_File"},{"location":"Examples/","text":"Return_Zero_Row_Tables source .Return_Zero_Row_Tables( model: pytabular.Tabular ) Returns list of table names of those that are returning isna() Args model (pytabular.Tabular) : Tabular Model Returns List of table names where DAX COUNTROWS('Table Name') is nan or 0. Table_Last_Refresh_Times source .Table_Last_Refresh_Times( model: pytabular.Tabular, group_partition: bool = True ) Returns pd.DataFrame of tables with their latest refresh time. Optional 'group_partition' variable, default is True. If False an extra column will be include to have the last refresh time to the grain of the partition Example to add to model model.Create_Table(p.Table_Last_Refresh_Times(model),'RefreshTimes') Args model (pytabular.Tabular) : Tabular Model group_partition (bool, optional) : Whether or not you want the grain of the dataframe to be by table or by partition. Defaults to True. Returns DataFrame : pd dataframe with the RefreshedTime property: https://docs.microsoft.com/en-us/dotnet/api/microsoft.analysisservices.tabular.partition.refreshedtime?view=analysisservices-dotnet#microsoft-analysisservices-tabular-partition-refreshedtime If group_partition == True and the table has multiple partitions, then df.groupby(by[\"tables\"]).max() BPA_Violations_To_DF source .BPA_Violations_To_DF( model: pytabular.Tabular, te2: str, bpa: str ) Runs BPA Analyzer from TE2 and outputs result into a DF. Args model (pytabular.Tabular) : Tabular Model Class te2 (str) : TE2 Exe File Path (Can use TE2().EXE_path) bpa (str) : BPA File Location (Can use BPA().Location) Returns DataFrame : Super simple right now. Just splits into two columns.. The object in violation and the rule. Last_X_Interval source .Last_X_Interval( Model: pytabular.Tabular, Measure: Union[str, pytabular.pytabular.Measure], Column_Name: Union[str, None] = None, Date_Column_Identifier: str = \"'Date'[DATE_DTE_KEY]\", Number_Of_Intervals: int = 90, Interval: str = 'DAY' ) Pulls the Last X Interval (Ex Last 90 Days) of a specific measure. Args Model (pytabular.Tabular) : Tabular Model to perform query on. Measure (Union[str,pytabular.pytabular.Measure]) : Measure to query. If string, will first check for a measure in the model with that name, otherwise will assume it is a DAX Expression (Ex SUM(FactTable[ColumnValue]) ) and perform that as expression Column_Name (Union[str,None], optional) : Column Name to be outputted in DataFrame. You can provide your own otherwise will take from the Measure Name. Defaults to \"Result\". Date_Column_Identifier (str, optional) : Date column dax identifier. Defaults to \"'Date'[DATE_DTE_KEY]\". Number_Of_Intervals (int, optional) : This is used to plug in the variables for DATESINPERIOD . Defaults to 90. Interval (str, optional) : Sames as Number_Of_Intervals. Used to plug in parameters of DAX function DATESINPERIOD . Defaults to \"DAY\". Possible options are \"DAY\", \"MONTH\", \"QUARTER\", and \"YEAR\" Returns DataFrame : Pandas DataFrame of results.","title":"Examples"},{"location":"Examples/#_1","text":"","title":""},{"location":"Examples/#return_zero_row_tables","text":"source .Return_Zero_Row_Tables( model: pytabular.Tabular ) Returns list of table names of those that are returning isna() Args model (pytabular.Tabular) : Tabular Model Returns List of table names where DAX COUNTROWS('Table Name') is nan or 0.","title":"Return_Zero_Row_Tables"},{"location":"Examples/#table_last_refresh_times","text":"source .Table_Last_Refresh_Times( model: pytabular.Tabular, group_partition: bool = True ) Returns pd.DataFrame of tables with their latest refresh time. Optional 'group_partition' variable, default is True. If False an extra column will be include to have the last refresh time to the grain of the partition Example to add to model model.Create_Table(p.Table_Last_Refresh_Times(model),'RefreshTimes') Args model (pytabular.Tabular) : Tabular Model group_partition (bool, optional) : Whether or not you want the grain of the dataframe to be by table or by partition. Defaults to True. Returns DataFrame : pd dataframe with the RefreshedTime property: https://docs.microsoft.com/en-us/dotnet/api/microsoft.analysisservices.tabular.partition.refreshedtime?view=analysisservices-dotnet#microsoft-analysisservices-tabular-partition-refreshedtime If group_partition == True and the table has multiple partitions, then df.groupby(by[\"tables\"]).max()","title":"Table_Last_Refresh_Times"},{"location":"Examples/#bpa_violations_to_df","text":"source .BPA_Violations_To_DF( model: pytabular.Tabular, te2: str, bpa: str ) Runs BPA Analyzer from TE2 and outputs result into a DF. Args model (pytabular.Tabular) : Tabular Model Class te2 (str) : TE2 Exe File Path (Can use TE2().EXE_path) bpa (str) : BPA File Location (Can use BPA().Location) Returns DataFrame : Super simple right now. Just splits into two columns.. The object in violation and the rule.","title":"BPA_Violations_To_DF"},{"location":"Examples/#last_x_interval","text":"source .Last_X_Interval( Model: pytabular.Tabular, Measure: Union[str, pytabular.pytabular.Measure], Column_Name: Union[str, None] = None, Date_Column_Identifier: str = \"'Date'[DATE_DTE_KEY]\", Number_Of_Intervals: int = 90, Interval: str = 'DAY' ) Pulls the Last X Interval (Ex Last 90 Days) of a specific measure. Args Model (pytabular.Tabular) : Tabular Model to perform query on. Measure (Union[str,pytabular.pytabular.Measure]) : Measure to query. If string, will first check for a measure in the model with that name, otherwise will assume it is a DAX Expression (Ex SUM(FactTable[ColumnValue]) ) and perform that as expression Column_Name (Union[str,None], optional) : Column Name to be outputted in DataFrame. You can provide your own otherwise will take from the Measure Name. Defaults to \"Result\". Date_Column_Identifier (str, optional) : Date column dax identifier. Defaults to \"'Date'[DATE_DTE_KEY]\". Number_Of_Intervals (int, optional) : This is used to plug in the variables for DATESINPERIOD . Defaults to 90. Interval (str, optional) : Sames as Number_Of_Intervals. Used to plug in parameters of DAX function DATESINPERIOD . Defaults to \"DAY\". Possible options are \"DAY\", \"MONTH\", \"QUARTER\", and \"YEAR\" Returns DataFrame : Pandas DataFrame of results.","title":"Last_X_Interval"},{"location":"Logic%20Utils/","text":"ticks_to_datetime source .ticks_to_datetime( ticks: int ) Converts a C# System DateTime Tick into a Python DateTime Args ticks (int) : C# DateTime Tick Returns datetime : datetime.datetime pandas_datatype_to_tabular_datatype source .pandas_datatype_to_tabular_datatype( df: pd.DataFrame ) WiP takes dataframe columns and gets respective tabular column datatype. ( NumPy Datatypes and Tabular Datatypes ) Args df (pd.DataFrame) : Pandas DataFrame Returns Dict : EX {'col1': , 'col2': , 'col3': } pd_dataframe_to_m_expression source .pd_dataframe_to_m_expression( df: pd.DataFrame ) This will take a pandas dataframe and convert to an m expression For example this DF: col1 col2 0 1 3 1 2 4 | | V Will convert to this expression string: let Source=#table({\"col1\",\"col2\"}, { {\"1\",\"3\"},{\"2\",\"4\"} }) in Source Args df (pd.DataFrame) : Pandas DataFrame Returns str : Currently only returning string values in your tabular model. remove_folder_and_contents source .remove_folder_and_contents( folder_location ) Internal used in tabular_editor.py and best_practice_analyzer.py. Args folder_location (str) : Folder path to remove directory and contents. remove_suffix source .remove_suffix( input_string, suffix ) Adding for >3.9 compatiblity. (Stackoverflow Answer)[https://stackoverflow.com/questions/66683630/removesuffix-returns-error-str-object-has-no-attribute-removesuffix] Args input_string (str) : input string to remove suffix from suffix (str) : suffix to be removed Returns str : input_str with suffix removed","title":"Logic Utils"},{"location":"Logic%20Utils/#_1","text":"","title":""},{"location":"Logic%20Utils/#ticks_to_datetime","text":"source .ticks_to_datetime( ticks: int ) Converts a C# System DateTime Tick into a Python DateTime Args ticks (int) : C# DateTime Tick Returns datetime : datetime.datetime","title":"ticks_to_datetime"},{"location":"Logic%20Utils/#pandas_datatype_to_tabular_datatype","text":"source .pandas_datatype_to_tabular_datatype( df: pd.DataFrame ) WiP takes dataframe columns and gets respective tabular column datatype. ( NumPy Datatypes and Tabular Datatypes ) Args df (pd.DataFrame) : Pandas DataFrame Returns Dict : EX {'col1': , 'col2': , 'col3': }","title":"pandas_datatype_to_tabular_datatype"},{"location":"Logic%20Utils/#pd_dataframe_to_m_expression","text":"source .pd_dataframe_to_m_expression( df: pd.DataFrame ) This will take a pandas dataframe and convert to an m expression For example this DF: col1 col2 0 1 3 1 2 4 | | V Will convert to this expression string: let Source=#table({\"col1\",\"col2\"}, { {\"1\",\"3\"},{\"2\",\"4\"} }) in Source Args df (pd.DataFrame) : Pandas DataFrame Returns str : Currently only returning string values in your tabular model.","title":"pd_dataframe_to_m_expression"},{"location":"Logic%20Utils/#remove_folder_and_contents","text":"source .remove_folder_and_contents( folder_location ) Internal used in tabular_editor.py and best_practice_analyzer.py. Args folder_location (str) : Folder path to remove directory and contents.","title":"remove_folder_and_contents"},{"location":"Logic%20Utils/#remove_suffix","text":"source .remove_suffix( input_string, suffix ) Adding for >3.9 compatiblity. (Stackoverflow Answer)[https://stackoverflow.com/questions/66683630/removesuffix-returns-error-str-object-has-no-attribute-removesuffix] Args input_string (str) : input string to remove suffix from suffix (str) : suffix to be removed Returns str : input_str with suffix removed","title":"remove_suffix"},{"location":"Tabular%20Editor%202/","text":"Tabular_Editor source Tabular_Editor( EXE_File_Path: str = 'Default' ) Setting Tabular_Editor Class for future work. Download_Tabular_Editor source .Download_Tabular_Editor( Download_Location: str = 'https: //github.com/TabularEditor/TabularEditor/releases/download/2.16.7/TabularEditor.Portable.zip', Folder: str = 'Tabular_Editor_2', Auto_Remove = True ) Runs a request.get() to retrieve the zip file from web. Will unzip response and store in directory. Will also register the removal of the new directory and files when exiting program. Args Download_Location (str, optional) : File path for zip of Tabular Editor 2. Defaults to [Tabular Editor 2 Github Zip Location]'https://github.com/TabularEditor/TabularEditor/releases/download/2.16.7/TabularEditor.Portable.zip'. Folder (str, optional) : New Folder Location. Defaults to 'Tabular_Editor_2'. Auto_Remove (bool, optional) : Boolean to determine auto removal of files once script exits. Defaults to True. Returns str : File path of TabularEditor.exe","title":"Tabular Editor"},{"location":"Tabular%20Editor%202/#_1","text":"","title":""},{"location":"Tabular%20Editor%202/#tabular_editor","text":"source Tabular_Editor( EXE_File_Path: str = 'Default' ) Setting Tabular_Editor Class for future work.","title":"Tabular_Editor"},{"location":"Tabular%20Editor%202/#download_tabular_editor","text":"source .Download_Tabular_Editor( Download_Location: str = 'https: //github.com/TabularEditor/TabularEditor/releases/download/2.16.7/TabularEditor.Portable.zip', Folder: str = 'Tabular_Editor_2', Auto_Remove = True ) Runs a request.get() to retrieve the zip file from web. Will unzip response and store in directory. Will also register the removal of the new directory and files when exiting program. Args Download_Location (str, optional) : File path for zip of Tabular Editor 2. Defaults to [Tabular Editor 2 Github Zip Location]'https://github.com/TabularEditor/TabularEditor/releases/download/2.16.7/TabularEditor.Portable.zip'. Folder (str, optional) : New Folder Location. Defaults to 'Tabular_Editor_2'. Auto_Remove (bool, optional) : Boolean to determine auto removal of files once script exits. Defaults to True. Returns str : File path of TabularEditor.exe","title":"Download_Tabular_Editor"},{"location":"Tabular/","text":"Tabular source Tabular( CONNECTION_STR: str ) Tabular Class to perform operations: Microsoft.AnalysisServices.Tabular . You can use this class as your main way to interact with your model. Args CONNECTION_STR (str) : Valid Connection String for connecting to a Tabular Model. Attributes Server (Server) : See Server MS Docs . Catalog (str) : Name of Database. See Catalog MS Docs . Model (Model) : See Model MS Docs . AdomdConnection (AdomdConnection) : For querying. See AdomdConnection MS Docs . Connection made from parts of the originally provided connection string. Tables (List[Table]) : Easy access list of tables from model. See Table MS Docs . Columns (List[Column]) : Easy access list of columns from model. See Column MS Docs . Partitions (List[Partition]) : Easy access list of partitions from model. See Partition MS Docs . Measures (List[Measure]) : Easy access list of measures from model. See Measure MS Docs . Methods: .Reload_Model_Info source .Reload_Model_Info() Runs on init iterates through details, can be called after any model changes. Called in SaveChanges() Returns bool : True if successful .Is_Process source .Is_Process() Run method to check if Processing is occurring. Will query DMV $SYSTEM.DISCOVER_JOBS to see if any processing is happening. Returns bool : True if DMV shows Process, False if not. .Disconnect source .Disconnect() Disconnects from Model Returns bool : True if successful .Refresh source .Refresh( Object: Union[str, Table, Partition, Dict[str, Any]], RefreshType: RefreshType = RefreshType.Full, Tracing = False ) Refreshes table(s) and partition(s). Args Object (Union[ str, Table, Partition, Dict[str, Any], Iterable[str, Table, Partition, Dict[str, Any]] ]) : Designed to handle a few different ways of selecting a refresh. RefreshType (RefreshType, optional) : See RefreshType . Defaults to RefreshType.Full. Tracing (bool, optional) : Currently just some basic tracing to track refreshes. Defaults to False. str == 'Table_Name' Table == Table Object Partition == Partition Object Dict[str, Any] == A way to specify a partition of group of partitions. For ex. {'Table_Name':'Partition1'} or {'Table_Name':['Partition1','Partition2']}. NOTE you can also change out the strings for partition or tables objects. Raises Exception : Raises exception if unable to find table or partition via string. Returns WIP : WIP .Update source .Update( UpdateOptions: UpdateOptions = UpdateOptions.ExpandFull ) Update Model Args UpdateOptions (UpdateOptions, optional) : See above MS Doc link. Defaults to UpdateOptions.ExpandFull. Returns None : Placeholder to eventually change. .SaveChanges source .SaveChanges() .Backup_Table source .Backup_Table( table_str: str ) USE WITH CAUTION, EXPERIMENTAL. Backs up table in memory, brings with it measures, columns, hierarchies, relationships, roles, etc. It will add suffix '_backup' to all objects. Refresh is performed from source during backup. Args table_str (str, optional) : Name of Table. Returns bool : Returns True if Successful, else will return error. .Revert_Table source .Revert_Table( table_str: str ) USE WITH CAUTION, EXPERIMENTAL. This is used in conjunction with Backup_Table(). It will take the 'TableName_backup' and replace with the original. Example scenario -> 1. model.Backup_Table('TableName') 2. perform any proposed changes in original 'TableName' 3. validate changes in 'TableName' 4. if unsuccessful run model.Revert_Table('TableName') Args table_str (str) : Name of table. Returns bool : Returns True if Successful, else will return error. .Query source .Query( Query_Str: str ) Executes Query on Model and Returns Results in Pandas DataFrame Args Query_Str (str) : Dax Query. Note, needs full syntax (ex: EVALUATE). See (DAX Queries)[https://docs.microsoft.com/en-us/dax/dax-queries]. Will check if query string is a file. If it is, then it will perform a query on whatever is read from the file. It is also possible to query DMV. For example. Query(\"select * from $SYSTEM.DISCOVER_TRACE_EVENT_CATEGORIES\"). See (DMVs)[https://docs.microsoft.com/en-us/analysis-services/instances/use-dynamic-management-views-dmvs-to-monitor-analysis-services?view=asallproducts-allversions] Returns DataFrame : Returns dataframe with results .Query_Every_Column source .Query_Every_Column( query_function: str = 'COUNTROWS(VALUES(_))' ) This will dynamically create a query to pull all columns from the model and run the query function. It will replace the _ with the column to run. Args query_function (str, optional) : Dax query is dynamically building a query with the UNION & ROW DAX Functions. Returns DataFrame : Returns dataframe with results. .Query_Every_Table source .Query_Every_Table( query_function: str = 'COUNTROWS(_)' ) This will dynamically create a query to pull all tables from the model and run the query function. It will replace the _ with the table to run. Args query_function (str, optional) : Dax query is dynamically building a query with the UNION & ROW DAX Functions. Defaults to 'COUNTROWS(_)'. Returns DataFrame : Returns dataframe with results .Analyze_BPA source .Analyze_BPA( Tabular_Editor_Exe: str, Best_Practice_Analyzer: str ) Takes your Tabular Model and performs TE2s BPA. Runs through Command line. Tabular Editor BPA Tabular Editor Command Line Options Args Tabular_Editor_Exe (str) : TE2 Exe File path. Feel free to use class TE2().EXE_Path or provide your own. Best_Practice_Analyzer (str) : BPA json file path. Feel free to use class BPA().Location or provide your own. Defualts to https://raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json Returns Assuming no failure, will return list of BPA violations. Else will return error from command line. .Create_Table source .Create_Table( df: pd.DataFrame, table_name: str ) Creates tables from pd.DataFrame as an M-Partition. So will convert the dataframe to M-Partition logic via the M query table constructor. Runs refresh and will update model. Args df (pd.DataFrame) : DataFrame to add to model table_name (str) : description Returns bool : True if successful","title":"Tabular"},{"location":"Tabular/#_1","text":"","title":""},{"location":"Tabular/#tabular","text":"source Tabular( CONNECTION_STR: str ) Tabular Class to perform operations: Microsoft.AnalysisServices.Tabular . You can use this class as your main way to interact with your model. Args CONNECTION_STR (str) : Valid Connection String for connecting to a Tabular Model. Attributes Server (Server) : See Server MS Docs . Catalog (str) : Name of Database. See Catalog MS Docs . Model (Model) : See Model MS Docs . AdomdConnection (AdomdConnection) : For querying. See AdomdConnection MS Docs . Connection made from parts of the originally provided connection string. Tables (List[Table]) : Easy access list of tables from model. See Table MS Docs . Columns (List[Column]) : Easy access list of columns from model. See Column MS Docs . Partitions (List[Partition]) : Easy access list of partitions from model. See Partition MS Docs . Measures (List[Measure]) : Easy access list of measures from model. See Measure MS Docs . Methods:","title":"Tabular"},{"location":"Tabular/#reload_model_info","text":"source .Reload_Model_Info() Runs on init iterates through details, can be called after any model changes. Called in SaveChanges() Returns bool : True if successful","title":".Reload_Model_Info"},{"location":"Tabular/#is_process","text":"source .Is_Process() Run method to check if Processing is occurring. Will query DMV $SYSTEM.DISCOVER_JOBS to see if any processing is happening. Returns bool : True if DMV shows Process, False if not.","title":".Is_Process"},{"location":"Tabular/#disconnect","text":"source .Disconnect() Disconnects from Model Returns bool : True if successful","title":".Disconnect"},{"location":"Tabular/#refresh","text":"source .Refresh( Object: Union[str, Table, Partition, Dict[str, Any]], RefreshType: RefreshType = RefreshType.Full, Tracing = False ) Refreshes table(s) and partition(s). Args Object (Union[ str, Table, Partition, Dict[str, Any], Iterable[str, Table, Partition, Dict[str, Any]] ]) : Designed to handle a few different ways of selecting a refresh. RefreshType (RefreshType, optional) : See RefreshType . Defaults to RefreshType.Full. Tracing (bool, optional) : Currently just some basic tracing to track refreshes. Defaults to False. str == 'Table_Name' Table == Table Object Partition == Partition Object Dict[str, Any] == A way to specify a partition of group of partitions. For ex. {'Table_Name':'Partition1'} or {'Table_Name':['Partition1','Partition2']}. NOTE you can also change out the strings for partition or tables objects. Raises Exception : Raises exception if unable to find table or partition via string. Returns WIP : WIP","title":".Refresh"},{"location":"Tabular/#update","text":"source .Update( UpdateOptions: UpdateOptions = UpdateOptions.ExpandFull ) Update Model Args UpdateOptions (UpdateOptions, optional) : See above MS Doc link. Defaults to UpdateOptions.ExpandFull. Returns None : Placeholder to eventually change.","title":".Update"},{"location":"Tabular/#savechanges","text":"source .SaveChanges()","title":".SaveChanges"},{"location":"Tabular/#backup_table","text":"source .Backup_Table( table_str: str ) USE WITH CAUTION, EXPERIMENTAL. Backs up table in memory, brings with it measures, columns, hierarchies, relationships, roles, etc. It will add suffix '_backup' to all objects. Refresh is performed from source during backup. Args table_str (str, optional) : Name of Table. Returns bool : Returns True if Successful, else will return error.","title":".Backup_Table"},{"location":"Tabular/#revert_table","text":"source .Revert_Table( table_str: str ) USE WITH CAUTION, EXPERIMENTAL. This is used in conjunction with Backup_Table(). It will take the 'TableName_backup' and replace with the original. Example scenario -> 1. model.Backup_Table('TableName') 2. perform any proposed changes in original 'TableName' 3. validate changes in 'TableName' 4. if unsuccessful run model.Revert_Table('TableName') Args table_str (str) : Name of table. Returns bool : Returns True if Successful, else will return error.","title":".Revert_Table"},{"location":"Tabular/#query","text":"source .Query( Query_Str: str ) Executes Query on Model and Returns Results in Pandas DataFrame Args Query_Str (str) : Dax Query. Note, needs full syntax (ex: EVALUATE). See (DAX Queries)[https://docs.microsoft.com/en-us/dax/dax-queries]. Will check if query string is a file. If it is, then it will perform a query on whatever is read from the file. It is also possible to query DMV. For example. Query(\"select * from $SYSTEM.DISCOVER_TRACE_EVENT_CATEGORIES\"). See (DMVs)[https://docs.microsoft.com/en-us/analysis-services/instances/use-dynamic-management-views-dmvs-to-monitor-analysis-services?view=asallproducts-allversions] Returns DataFrame : Returns dataframe with results","title":".Query"},{"location":"Tabular/#query_every_column","text":"source .Query_Every_Column( query_function: str = 'COUNTROWS(VALUES(_))' ) This will dynamically create a query to pull all columns from the model and run the query function. It will replace the _ with the column to run. Args query_function (str, optional) : Dax query is dynamically building a query with the UNION & ROW DAX Functions. Returns DataFrame : Returns dataframe with results.","title":".Query_Every_Column"},{"location":"Tabular/#query_every_table","text":"source .Query_Every_Table( query_function: str = 'COUNTROWS(_)' ) This will dynamically create a query to pull all tables from the model and run the query function. It will replace the _ with the table to run. Args query_function (str, optional) : Dax query is dynamically building a query with the UNION & ROW DAX Functions. Defaults to 'COUNTROWS(_)'. Returns DataFrame : Returns dataframe with results","title":".Query_Every_Table"},{"location":"Tabular/#analyze_bpa","text":"source .Analyze_BPA( Tabular_Editor_Exe: str, Best_Practice_Analyzer: str ) Takes your Tabular Model and performs TE2s BPA. Runs through Command line. Tabular Editor BPA Tabular Editor Command Line Options Args Tabular_Editor_Exe (str) : TE2 Exe File path. Feel free to use class TE2().EXE_Path or provide your own. Best_Practice_Analyzer (str) : BPA json file path. Feel free to use class BPA().Location or provide your own. Defualts to https://raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json Returns Assuming no failure, will return list of BPA violations. Else will return error from command line.","title":".Analyze_BPA"},{"location":"Tabular/#create_table","text":"source .Create_Table( df: pd.DataFrame, table_name: str ) Creates tables from pd.DataFrame as an M-Partition. So will convert the dataframe to M-Partition logic via the M query table constructor. Runs refresh and will update model. Args df (pd.DataFrame) : DataFrame to add to model table_name (str) : description Returns bool : True if successful","title":".Create_Table"},{"location":"Traces/","text":"Base_Trace source Base_Trace( Tabular_Class, Trace_Events: List[TraceEvent], Trace_Event_Columns: List[TraceColumn], Handler: Callable ) Generates Trace to be run on Server. This is the base class to customize the type of Trace you are looking for. Server Traces Args Tabular_Class (Tabular) : Tabular Class. Trace_Events (List[TraceEvent]) : List of Trace Events. Trace_Event_Columns (List[TraceColumn]) : List of Trace Event Columns. Handler (Callable) : Function to call when Trace returns response. TraceEventClass TraceEventColumn Input needs to be two arguments. One is source (Which is currently None... Need to investigate why). Second is TraceEventArgs Methods: .Build source .Build() Run on initialization. This will take the inputed arguments for the class and attempt to build the Trace. Returns bool : True if successful .Arguments source .Arguments( Trace_Events: List[TraceEvent], Trace_Event_Columns: List[TraceColumn], Handler: Callable ) .Add source .Add() Runs on initialization. Adds built Trace to the Server. Returns int : Return int of placement in Server.Traces.get_Item(int) .Update source .Update() Runs on initialization. Syncs with Server. Returns None : Returns None. Unless unsuccessful then it will return the error from Server. .Start source .Start() Call when you want to start the Trace Returns None : Returns None. Unless unsuccessful then it will return the error from Server. .Stop source .Stop() Call when you want to stop the Trace Returns None : Returns None. Unless unsuccessful then it will return the error from Server. .Drop source .Drop() Call when you want to drop the Trace Returns None : Returns None. Unless unsuccessful, then it will return the error from Server. Refresh_Trace source Refresh_Trace( Tabular_Class, Trace_Events: List[TraceEvent] = [TraceEventClass.ProgressReportBegin, TraceEventClass.ProgressReportCurrent, TraceEventClass.ProgressReportEnd, TraceEventClass.ProgressReportError], Trace_Event_Columns: List[TraceColumn] = [TraceColumn.EventSubclass, TraceColumn.CurrentTime, TraceColumn.ObjectName, TraceColumn.ObjectPath, TraceColumn.DatabaseName, TraceColumn.SessionID, TraceColumn.TextData, TraceColumn.EventClass, TraceColumn.ProgressTotal], Handler: Callable = refresh_handler ) Subclass of Base_Trace. For built-in Refresh Tracing. Args Base_Trace ( type ) : description","title":"Trace"},{"location":"Traces/#_1","text":"","title":""},{"location":"Traces/#base_trace","text":"source Base_Trace( Tabular_Class, Trace_Events: List[TraceEvent], Trace_Event_Columns: List[TraceColumn], Handler: Callable ) Generates Trace to be run on Server. This is the base class to customize the type of Trace you are looking for. Server Traces Args Tabular_Class (Tabular) : Tabular Class. Trace_Events (List[TraceEvent]) : List of Trace Events. Trace_Event_Columns (List[TraceColumn]) : List of Trace Event Columns. Handler (Callable) : Function to call when Trace returns response. TraceEventClass TraceEventColumn Input needs to be two arguments. One is source (Which is currently None... Need to investigate why). Second is TraceEventArgs Methods:","title":"Base_Trace"},{"location":"Traces/#build","text":"source .Build() Run on initialization. This will take the inputed arguments for the class and attempt to build the Trace. Returns bool : True if successful","title":".Build"},{"location":"Traces/#arguments","text":"source .Arguments( Trace_Events: List[TraceEvent], Trace_Event_Columns: List[TraceColumn], Handler: Callable )","title":".Arguments"},{"location":"Traces/#add","text":"source .Add() Runs on initialization. Adds built Trace to the Server. Returns int : Return int of placement in Server.Traces.get_Item(int)","title":".Add"},{"location":"Traces/#update","text":"source .Update() Runs on initialization. Syncs with Server. Returns None : Returns None. Unless unsuccessful then it will return the error from Server.","title":".Update"},{"location":"Traces/#start","text":"source .Start() Call when you want to start the Trace Returns None : Returns None. Unless unsuccessful then it will return the error from Server.","title":".Start"},{"location":"Traces/#stop","text":"source .Stop() Call when you want to stop the Trace Returns None : Returns None. Unless unsuccessful then it will return the error from Server.","title":".Stop"},{"location":"Traces/#drop","text":"source .Drop() Call when you want to drop the Trace Returns None : Returns None. Unless unsuccessful, then it will return the error from Server.","title":".Drop"},{"location":"Traces/#refresh_trace","text":"source Refresh_Trace( Tabular_Class, Trace_Events: List[TraceEvent] = [TraceEventClass.ProgressReportBegin, TraceEventClass.ProgressReportCurrent, TraceEventClass.ProgressReportEnd, TraceEventClass.ProgressReportError], Trace_Event_Columns: List[TraceColumn] = [TraceColumn.EventSubclass, TraceColumn.CurrentTime, TraceColumn.ObjectName, TraceColumn.ObjectPath, TraceColumn.DatabaseName, TraceColumn.SessionID, TraceColumn.TextData, TraceColumn.EventClass, TraceColumn.ProgressTotal], Handler: Callable = refresh_handler ) Subclass of Base_Trace. For built-in Refresh Tracing. Args Base_Trace ( type ) : description","title":"Refresh_Trace"},{"location":"contributing/","text":"Contributing Guidelines Work will be distributed under MIT license Pull request into main will run a flake8 test. flake8 will need to pass before pull request will be accepted Updates of any kind are welcome! Even just letting me know of the issues. Or updating doc strings Limit any external modules, see pyproject.toml for dependencies Goal of project is to help connect the python world and the tabular model world for some easier programmatic execution on models. Docstrings follow google docstring format See actions, once main updated, mkgendocs is used to auto create documentation","title":"Contributing Guidelines"},{"location":"contributing/#contributing-guidelines","text":"Work will be distributed under MIT license Pull request into main will run a flake8 test. flake8 will need to pass before pull request will be accepted Updates of any kind are welcome! Even just letting me know of the issues. Or updating doc strings Limit any external modules, see pyproject.toml for dependencies Goal of project is to help connect the python world and the tabular model world for some easier programmatic execution on models. Docstrings follow google docstring format See actions, once main updated, mkgendocs is used to auto create documentation","title":"Contributing Guidelines"}]}