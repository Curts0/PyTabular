{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PyTabular What is it? PyTabular (python-tabular in pypi ) is a python package that allows for programmatic execution on your tabular models! This is possible thanks to Pythonnet and Microsoft's .Net APIs on Azure Analysis Services . Currently, this build is tested and working on Windows Operating System only. Help is needed to expand this for other operating systems. The package should have the dll files included when you import it. See Documentation Here . PyTabular is still considered alpha while I'm working on building out the proper tests and testing environments, so I can ensure some kind of stability in features. Please send bugs my way! Preferably in the issues section in Github. I want to harden this project so many can use it easily. I currently have local pytest for python 3.6 to 3.10 and run those tests through a local AAS and Gen2 model. Getting Started See the Pypi project for available version. python3 -m pip install python-tabular In your python environment, import pytabular and call the main Tabular Class. Only parameter needed is a solid connection string. import pytabular model = pytabular.Tabular(CONNECTION_STR) I'm a big fan of logging, if you don't want any just get the logger and disable it. import pytabular pytabular.logger.disabled = True You can query your models with the Query method from your tabular class. For Dax Queries, it will need the full Dax syntax. See EVALUATE example . This will return a Pandas DataFrame . If you are looking to return a single value, see below. Simply wrap your query in the the curly brackets. The method will take that single cell table and just return the individual value. You can also query your DMV. See below for example. See PyTabular Docs for Query . #Run basic queries DAX_QUERY = \"EVALUATE TOPN(100, 'Table1')\" model.Query(DAX_QUERY) #returns pd.DataFrame() #or... DMV_QUERY = \"select * from $SYSTEM.DISCOVER_TRACE_EVENT_CATEGORIES\" model.Query(DMV_QUERY) #returns pd.DataFrame() #or... SINGLE_VALUE_QUERY_EX = \"EVALUATE {1}\" model.Query(SINGLE_VALUE_QUERY_EX) #returns 1 #or... FILE_PATH = 'C:\\\\FILEPATHEXAMPLE\\\\file.dax' #or file.txt model.Query(FILE_PATH) #Will return same logic as above, single values if possible else will return pd.DataFrame() You can also explore your tables, partitions, and columns. Via the Attributes from your Tabular class. #Explore tables... dir(model.Tables['Table Name']) #Explore columns & partitions dir(model.Tables['Table Name'].Partitions['Partition Name']) #Only a few features right now, but check out the built in methods. model.Tables['Table Name'].Refresh(Tracing = True) #or model.Tables['Table Name'].Partitions['Partition Name'].Refresh(Tracing = True) #or model.Tables['Table Name'].Partitions['Partition Name'].Last_Refresh() #or model.Tables['Table Name'].Row_Count() #or model.Tables['Table Name'].Columns['Column Name'].Distinct_Count() Refresh method to handle refreshes on your model. This is synchronous. Should be flexible enough to handle a variety of inputs. See PyTabular Docs for Refreshing Tables and Partitions . Most basic way to refresh is input the table name string. The method will search for table and output exeption if unable to find it. For partitions you will need a key, value combination. Example, {'Table1':'Partition1'}. You can also take the key value pair and iterate through a group of partitions. Example, {'Table1':['Partition1','Partition2']}. Rather than providing a string, you can also input the actual class. See below for those examples, and you can acess them from the built in attributes self.Tables, self.Partitions or explore through the .Net classes yourself in self.Model.Tables. #You have a few options when refreshing. model.Refresh('Table Name') #or... model.Refresh(['Table1','Table2','Table3']) #or... model.Refresh(<Table Class>) #or... model.Refresh(<Partition Class>) #or... model.Refresh({'Table Name':'Partition Name'}) #or any kind of weird combination like model.Refresh([{<Table Class>:<Partition Class>,'Table Name':['Partition1','Partition2']},'Table Name','Table Name2']) #You can even run through the Tables & Partition Attributes model.Tables['Table Name'].Refresh() #or model.Tables['Table Name'].Partitions['Partition Name'].Refresh() #Default Tracing happens automatically, but can be removed by -- model.Refresh(['Table1','Table2'], trace = None) It's not uncommon to need to run through some checks on specific Tables, Partitions, Columns, Etc... #Get Row Count from model model.Tables['Table Name'].Row_Count() #Get Last Refresh time from a partition model.Tables['Table Name'].Last_Refresh() #Get Distinct Count or Values from a Column model.Tables['Table Name'].Columns['Column Name'].Distinct_Count() #or model.Tables['Table Name'].Columns['Column Name'].Values() Use Cases If blank table, then refresh table. This will use the function Return_Zero_Row_Tables and the method Refresh from the Tabular class. import pytabular model = pytabular.Tabular(CONNECTION_STR) tables = pytabular.Return_Zero_Row_Tables(model) if len(tables) > 0: model.Refresh(tables, Tracing = True) #Add a trace in there for some fun. Sneak in a refresh. This will use the method Is_Process and the method Refresh from the Tabular class. It will check the DMV to see if any jobs are currently running classified as processing. import pytabular model = pytabular.Tabular(CONNECTION_STR) if model.Is_Process(): #do what you want if there is a refresh happening else: model.Refresh(TABLES_OR_PARTITIONS_TO_REFRESH) Show refresh times in model. This will use the function Table_Last_Refresh_Times and the method Create_Table from the Tabular class. It will search through the model for all tables and partitions and pull the 'RefreshedTime' property from it. It will return results into a pandas dataframe, which will then be converted into an M expression used for a new table. import pytabular model = pytabular.Tabular(CONNECTION_STR) df = pytabular.Table_Last_Refresh_Times(model, group_partition = False) model.Create_Table(df, 'Refresh Times') If BPA Violation, then revert deployment. Uses a few things. First the BPA Class , then the TE2 Class , and will finish with the Analyze_BPA method. Did not want to re-invent the wheel with the amazing work done with Tabular Editor and it's BPA capabilities. import pytabular model = pytabular.Tabular(CONNECTION_STR) TE2 = pytabular.Tabular_Editor() #Feel free to input your TE2 File path or this will download for you. BPA = pytabular.BPA() #Fee free to input your own BPA file or this will download for you from: https://raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json results = model.Analyze_BPA(TE2.EXE,BPA.Location) if len(results) > 0: #Revert deployment here! Backup & Revert a Table. USE WITH CAUTION, obviously not in PROD. I have been experimenting with this concept. Made for selfish reasons. Will probably get removed and I'll keep in my own local version. But fun to work with. Uses two methods. Backup_Table and Revert_Table import pytabular model = pytabular.Tabular(CONNECTION_STR) model.Backup_Table('TableName') #This will backup the table with surround items (columns,measures,relationships,roles,hierarchies,etc.) and will add a suffix of '_backup' #-----------# #Make any changes to your original table and then revert or delete backup as necessary #-----------# model.Revert_Table('TableName') #This will essentially replace your original with _backup Loop through and query Dax files Let's say you have multiple dax queries you would like to store and run through as checks. The Query method on the Tabular class can also take file paths. Can really be any file type as it's just checking os.path.isfile(). But would suggest .dax or .txt. It will read the file that use that as the new Query_str argument. import pytabular model = pytabular.Tabular(CONNECTION_STR) LIST_OF_FILE_PATHS = ['C:\\\\FilePath\\\\file1.dax','C:\\\\FilePath\\\\file1.txt','C:\\\\FilePath\\\\file2.dax','C:\\\\FilePath\\\\file2.txt'] for file_path in LIST_OF_FILE_PATHS: model.Query(file_path) Advanced Refreshing with Pre and Post Checks Maybe you are introducing new logic to a fact table, and you need to ensure that a measure checking last month values never changes. To do that you can take advantage of the Refresh_Check and Refresh_Check_Collection classes (Sorry, I know the documentation stinks right now). But using those you can build out something that would first check the results of the measure, then refresh, then check the results of the measure after refresh, and lastly perform your desired check. In this case the pre value matches the post value. When refreshing and your pre does not equal post, it would fail and give an assertion error in your logging. from pytabular import Tabular from pytabular.refresh import Refresh_Check, Refresh_Check_Collection model = Tabular(CONNECTION_STR) # This is our custom check that we want to run after refresh. # Does the pre refresh value match the post refresh value. def sum_of_sales_assertion(pre, post): return pre == post # This is where we put it all together into the `Refresh_Check` class. Give it a name, give it a query to run, and give it the assertion you want to make. sum_of_last_month_sales = Refresh_Check( 'Last Month Sales', lambda: model.Query(\"EVALUATE {[Last Month Sales]}\") ,sum_of_sales_assertion ) # Here we are adding it to a `Refresh_Check_Collection` because you can have more than on `Refresh_Check` to run. all_refresh_check = Refresh_Check_Collection([sum_of_last_month_sales]) model.Refresh( 'Fact Table Name', refresh_checks = Refresh_Check_Collection([sum_of_last_month_sales]) ) Query as Another User There are plenty of tools that allow you to query as an 'Effective User' inheriting their security when querying. This is an extremely valuable concept built natively into the .Net apis. My only gripe is they were all UI based. This allows you to programmatically connect as an effective user and query in Python. You could easily loop through all your users to run tests on their security. import pytabular as p #Connect to your model like usual... model = p.Tabular(CONNECTION_STR) #This will be the query I run... query_str = ''' EVALUATE SUMMARIZE( 'Product Dimension', 'Product Dimension'[Product Name], \"Total Product Sales\", [Total Sales] ) ''' #This will be the user I want to query as... user_email = 'user1@company.com' #Base line, to query as the user connecting to the model. model.Query(query_str) #Option 1, Connect via connection class... user1 = p.Connection(model.Server, Effective_User = user_email) user1.Query(query_str) #Option 2, Just add Effective_User model.Query(query_str, Effective_User = user_email) #PyTabular will do it's best to handle multiple accounts... #So you won't have to reconnect on every query Refresh Related Tables Ever need to refresh related tables of a Fact? Now should be a lot easier. import pytabular as p #Connect to model model = p.Tabular(CONNECTION_STR) #Get related tables tables = model.Tables[TABLE_NAME].Related() #Now just refresh like usual... tables.Refresh() Contributing See CONTRIBUTING.md","title":"Home"},{"location":"#pytabular","text":"","title":"PyTabular"},{"location":"#what-is-it","text":"PyTabular (python-tabular in pypi ) is a python package that allows for programmatic execution on your tabular models! This is possible thanks to Pythonnet and Microsoft's .Net APIs on Azure Analysis Services . Currently, this build is tested and working on Windows Operating System only. Help is needed to expand this for other operating systems. The package should have the dll files included when you import it. See Documentation Here . PyTabular is still considered alpha while I'm working on building out the proper tests and testing environments, so I can ensure some kind of stability in features. Please send bugs my way! Preferably in the issues section in Github. I want to harden this project so many can use it easily. I currently have local pytest for python 3.6 to 3.10 and run those tests through a local AAS and Gen2 model.","title":"What is it?"},{"location":"#getting-started","text":"See the Pypi project for available version. python3 -m pip install python-tabular In your python environment, import pytabular and call the main Tabular Class. Only parameter needed is a solid connection string. import pytabular model = pytabular.Tabular(CONNECTION_STR) I'm a big fan of logging, if you don't want any just get the logger and disable it. import pytabular pytabular.logger.disabled = True You can query your models with the Query method from your tabular class. For Dax Queries, it will need the full Dax syntax. See EVALUATE example . This will return a Pandas DataFrame . If you are looking to return a single value, see below. Simply wrap your query in the the curly brackets. The method will take that single cell table and just return the individual value. You can also query your DMV. See below for example. See PyTabular Docs for Query . #Run basic queries DAX_QUERY = \"EVALUATE TOPN(100, 'Table1')\" model.Query(DAX_QUERY) #returns pd.DataFrame() #or... DMV_QUERY = \"select * from $SYSTEM.DISCOVER_TRACE_EVENT_CATEGORIES\" model.Query(DMV_QUERY) #returns pd.DataFrame() #or... SINGLE_VALUE_QUERY_EX = \"EVALUATE {1}\" model.Query(SINGLE_VALUE_QUERY_EX) #returns 1 #or... FILE_PATH = 'C:\\\\FILEPATHEXAMPLE\\\\file.dax' #or file.txt model.Query(FILE_PATH) #Will return same logic as above, single values if possible else will return pd.DataFrame() You can also explore your tables, partitions, and columns. Via the Attributes from your Tabular class. #Explore tables... dir(model.Tables['Table Name']) #Explore columns & partitions dir(model.Tables['Table Name'].Partitions['Partition Name']) #Only a few features right now, but check out the built in methods. model.Tables['Table Name'].Refresh(Tracing = True) #or model.Tables['Table Name'].Partitions['Partition Name'].Refresh(Tracing = True) #or model.Tables['Table Name'].Partitions['Partition Name'].Last_Refresh() #or model.Tables['Table Name'].Row_Count() #or model.Tables['Table Name'].Columns['Column Name'].Distinct_Count() Refresh method to handle refreshes on your model. This is synchronous. Should be flexible enough to handle a variety of inputs. See PyTabular Docs for Refreshing Tables and Partitions . Most basic way to refresh is input the table name string. The method will search for table and output exeption if unable to find it. For partitions you will need a key, value combination. Example, {'Table1':'Partition1'}. You can also take the key value pair and iterate through a group of partitions. Example, {'Table1':['Partition1','Partition2']}. Rather than providing a string, you can also input the actual class. See below for those examples, and you can acess them from the built in attributes self.Tables, self.Partitions or explore through the .Net classes yourself in self.Model.Tables. #You have a few options when refreshing. model.Refresh('Table Name') #or... model.Refresh(['Table1','Table2','Table3']) #or... model.Refresh(<Table Class>) #or... model.Refresh(<Partition Class>) #or... model.Refresh({'Table Name':'Partition Name'}) #or any kind of weird combination like model.Refresh([{<Table Class>:<Partition Class>,'Table Name':['Partition1','Partition2']},'Table Name','Table Name2']) #You can even run through the Tables & Partition Attributes model.Tables['Table Name'].Refresh() #or model.Tables['Table Name'].Partitions['Partition Name'].Refresh() #Default Tracing happens automatically, but can be removed by -- model.Refresh(['Table1','Table2'], trace = None) It's not uncommon to need to run through some checks on specific Tables, Partitions, Columns, Etc... #Get Row Count from model model.Tables['Table Name'].Row_Count() #Get Last Refresh time from a partition model.Tables['Table Name'].Last_Refresh() #Get Distinct Count or Values from a Column model.Tables['Table Name'].Columns['Column Name'].Distinct_Count() #or model.Tables['Table Name'].Columns['Column Name'].Values()","title":"Getting Started"},{"location":"#use-cases","text":"","title":"Use Cases"},{"location":"#if-blank-table-then-refresh-table","text":"This will use the function Return_Zero_Row_Tables and the method Refresh from the Tabular class. import pytabular model = pytabular.Tabular(CONNECTION_STR) tables = pytabular.Return_Zero_Row_Tables(model) if len(tables) > 0: model.Refresh(tables, Tracing = True) #Add a trace in there for some fun.","title":"If blank table, then refresh table."},{"location":"#sneak-in-a-refresh","text":"This will use the method Is_Process and the method Refresh from the Tabular class. It will check the DMV to see if any jobs are currently running classified as processing. import pytabular model = pytabular.Tabular(CONNECTION_STR) if model.Is_Process(): #do what you want if there is a refresh happening else: model.Refresh(TABLES_OR_PARTITIONS_TO_REFRESH)","title":"Sneak in a refresh."},{"location":"#show-refresh-times-in-model","text":"This will use the function Table_Last_Refresh_Times and the method Create_Table from the Tabular class. It will search through the model for all tables and partitions and pull the 'RefreshedTime' property from it. It will return results into a pandas dataframe, which will then be converted into an M expression used for a new table. import pytabular model = pytabular.Tabular(CONNECTION_STR) df = pytabular.Table_Last_Refresh_Times(model, group_partition = False) model.Create_Table(df, 'Refresh Times')","title":"Show refresh times in model."},{"location":"#if-bpa-violation-then-revert-deployment","text":"Uses a few things. First the BPA Class , then the TE2 Class , and will finish with the Analyze_BPA method. Did not want to re-invent the wheel with the amazing work done with Tabular Editor and it's BPA capabilities. import pytabular model = pytabular.Tabular(CONNECTION_STR) TE2 = pytabular.Tabular_Editor() #Feel free to input your TE2 File path or this will download for you. BPA = pytabular.BPA() #Fee free to input your own BPA file or this will download for you from: https://raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json results = model.Analyze_BPA(TE2.EXE,BPA.Location) if len(results) > 0: #Revert deployment here!","title":"If BPA Violation, then revert deployment."},{"location":"#backup-revert-a-table","text":"USE WITH CAUTION, obviously not in PROD. I have been experimenting with this concept. Made for selfish reasons. Will probably get removed and I'll keep in my own local version. But fun to work with. Uses two methods. Backup_Table and Revert_Table import pytabular model = pytabular.Tabular(CONNECTION_STR) model.Backup_Table('TableName') #This will backup the table with surround items (columns,measures,relationships,roles,hierarchies,etc.) and will add a suffix of '_backup' #-----------# #Make any changes to your original table and then revert or delete backup as necessary #-----------# model.Revert_Table('TableName') #This will essentially replace your original with _backup","title":"Backup &amp; Revert a Table."},{"location":"#loop-through-and-query-dax-files","text":"Let's say you have multiple dax queries you would like to store and run through as checks. The Query method on the Tabular class can also take file paths. Can really be any file type as it's just checking os.path.isfile(). But would suggest .dax or .txt. It will read the file that use that as the new Query_str argument. import pytabular model = pytabular.Tabular(CONNECTION_STR) LIST_OF_FILE_PATHS = ['C:\\\\FilePath\\\\file1.dax','C:\\\\FilePath\\\\file1.txt','C:\\\\FilePath\\\\file2.dax','C:\\\\FilePath\\\\file2.txt'] for file_path in LIST_OF_FILE_PATHS: model.Query(file_path)","title":"Loop through and query Dax files"},{"location":"#advanced-refreshing-with-pre-and-post-checks","text":"Maybe you are introducing new logic to a fact table, and you need to ensure that a measure checking last month values never changes. To do that you can take advantage of the Refresh_Check and Refresh_Check_Collection classes (Sorry, I know the documentation stinks right now). But using those you can build out something that would first check the results of the measure, then refresh, then check the results of the measure after refresh, and lastly perform your desired check. In this case the pre value matches the post value. When refreshing and your pre does not equal post, it would fail and give an assertion error in your logging. from pytabular import Tabular from pytabular.refresh import Refresh_Check, Refresh_Check_Collection model = Tabular(CONNECTION_STR) # This is our custom check that we want to run after refresh. # Does the pre refresh value match the post refresh value. def sum_of_sales_assertion(pre, post): return pre == post # This is where we put it all together into the `Refresh_Check` class. Give it a name, give it a query to run, and give it the assertion you want to make. sum_of_last_month_sales = Refresh_Check( 'Last Month Sales', lambda: model.Query(\"EVALUATE {[Last Month Sales]}\") ,sum_of_sales_assertion ) # Here we are adding it to a `Refresh_Check_Collection` because you can have more than on `Refresh_Check` to run. all_refresh_check = Refresh_Check_Collection([sum_of_last_month_sales]) model.Refresh( 'Fact Table Name', refresh_checks = Refresh_Check_Collection([sum_of_last_month_sales]) )","title":"Advanced Refreshing with Pre and Post Checks"},{"location":"#query-as-another-user","text":"There are plenty of tools that allow you to query as an 'Effective User' inheriting their security when querying. This is an extremely valuable concept built natively into the .Net apis. My only gripe is they were all UI based. This allows you to programmatically connect as an effective user and query in Python. You could easily loop through all your users to run tests on their security. import pytabular as p #Connect to your model like usual... model = p.Tabular(CONNECTION_STR) #This will be the query I run... query_str = ''' EVALUATE SUMMARIZE( 'Product Dimension', 'Product Dimension'[Product Name], \"Total Product Sales\", [Total Sales] ) ''' #This will be the user I want to query as... user_email = 'user1@company.com' #Base line, to query as the user connecting to the model. model.Query(query_str) #Option 1, Connect via connection class... user1 = p.Connection(model.Server, Effective_User = user_email) user1.Query(query_str) #Option 2, Just add Effective_User model.Query(query_str, Effective_User = user_email) #PyTabular will do it's best to handle multiple accounts... #So you won't have to reconnect on every query","title":"Query as Another User"},{"location":"#refresh-related-tables","text":"Ever need to refresh related tables of a Fact? Now should be a lot easier. import pytabular as p #Connect to model model = p.Tabular(CONNECTION_STR) #Get related tables tables = model.Tables[TABLE_NAME].Related() #Now just refresh like usual... tables.Refresh()","title":"Refresh Related Tables"},{"location":"#contributing","text":"See CONTRIBUTING.md","title":"Contributing"},{"location":"Best%20Practice%20Analyzer/","text":"BPA source BPA( File_Path: str = 'Default' ) Setting BPA Class for future work... Download_BPA_File source .Download_BPA_File( Download_Location: str = 'https: //raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json', Folder: str = 'Best_Practice_Analyzer', Auto_Remove = True ) Runs a request.get() to retrieve the json file from web. Will return and store in directory. Will also register the removal of the new directory and file when exiting program. Args Download_Location ( type , optional) : F. Defaults to [Microsoft GitHub BPA]'https://raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json'. Folder (str, optional) : New Folder String. Defaults to 'Best_Practice_Analyzer'. Auto_Remove (bool, optional) : If you wish to Auto Remove when script exits. Defaults to True. Returns str : File Path for the newly downloaded BPA.","title":"Best Practice Analyzer"},{"location":"Best%20Practice%20Analyzer/#_1","text":"","title":""},{"location":"Best%20Practice%20Analyzer/#bpa","text":"source BPA( File_Path: str = 'Default' ) Setting BPA Class for future work...","title":"BPA"},{"location":"Best%20Practice%20Analyzer/#download_bpa_file","text":"source .Download_BPA_File( Download_Location: str = 'https: //raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json', Folder: str = 'Best_Practice_Analyzer', Auto_Remove = True ) Runs a request.get() to retrieve the json file from web. Will return and store in directory. Will also register the removal of the new directory and file when exiting program. Args Download_Location ( type , optional) : F. Defaults to [Microsoft GitHub BPA]'https://raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json'. Folder (str, optional) : New Folder String. Defaults to 'Best_Practice_Analyzer'. Auto_Remove (bool, optional) : If you wish to Auto Remove when script exits. Defaults to True. Returns str : File Path for the newly downloaded BPA.","title":"Download_BPA_File"},{"location":"Column/","text":"PyColumn source PyColumn( object, table ) Wrapper for Microsoft.AnalysisServices.Tabular.Column . With a few other bells and whistles added to it. WIP Args Table : Parent Table to the Column Methods: .Distinct_Count source .Distinct_Count( No_Blank = False ) Get DISTINCTCOUNT of Column. Args No_Blank (bool, optional) : Ability to call DISTINCTCOUNTNOBLANK . Defaults to False. Returns int : Number of Distinct Count from column. If No_Blank == True then will return number of Distinct Count no blanks. .Values source .Values() Get single column DataFrame of VALUES Returns DataFrame : Single Column DataFrame of Values. PyColumns source PyColumns( objects )","title":"Column"},{"location":"Column/#_1","text":"","title":""},{"location":"Column/#pycolumn","text":"source PyColumn( object, table ) Wrapper for Microsoft.AnalysisServices.Tabular.Column . With a few other bells and whistles added to it. WIP Args Table : Parent Table to the Column Methods:","title":"PyColumn"},{"location":"Column/#distinct_count","text":"source .Distinct_Count( No_Blank = False ) Get DISTINCTCOUNT of Column. Args No_Blank (bool, optional) : Ability to call DISTINCTCOUNTNOBLANK . Defaults to False. Returns int : Number of Distinct Count from column. If No_Blank == True then will return number of Distinct Count no blanks.","title":".Distinct_Count"},{"location":"Column/#values","text":"source .Values() Get single column DataFrame of VALUES Returns DataFrame : Single Column DataFrame of Values.","title":".Values"},{"location":"Column/#pycolumns","text":"source PyColumns( objects )","title":"PyColumns"},{"location":"Examples/","text":"Return_Zero_Row_Tables source .Return_Zero_Row_Tables( model: pytabular.Tabular ) Returns list of table names of those that are returning isna() Args model (pytabular.Tabular) : Tabular Model Returns List of table names where DAX COUNTROWS('Table Name') is nan or 0. Table_Last_Refresh_Times source .Table_Last_Refresh_Times( model: pytabular.Tabular, group_partition: bool = True ) Returns pd.DataFrame of tables with their latest refresh time. Optional 'group_partition' variable, default is True. If False an extra column will be include to have the last refresh time to the grain of the partition Example to add to model model.Create_Table(p.Table_Last_Refresh_Times(model),'RefreshTimes') Args model (pytabular.Tabular) : Tabular Model group_partition (bool, optional) : Whether or not you want the grain of the dataframe to be by table or by partition. Defaults to True. Returns DataFrame : pd dataframe with the RefreshedTime property: https://docs.microsoft.com/en-us/dotnet/api/microsoft.analysisservices.tabular.partition.refreshedtime?view=analysisservices-dotnet#microsoft-analysisservices-tabular-partition-refreshedtime If group_partition == True and the table has multiple partitions, then df.groupby(by[\"tables\"]).max() BPA_Violations_To_DF source .BPA_Violations_To_DF( model: pytabular.Tabular, te2: str, bpa: str ) Runs BPA Analyzer from TE2 and outputs result into a DF. Args model (pytabular.Tabular) : Tabular Model Class te2 (str) : TE2 Exe File Path (Can use TE2().EXE_path) bpa (str) : BPA File Location (Can use BPA().Location) Returns DataFrame : Super simple right now. Just splits into two columns.. The object in violation and the rule. Last_X_Interval source .Last_X_Interval( Model: pytabular.Tabular, Measure: Union[str, PyMeasure], Column_Name: Union[str, None] = None, Date_Column_Identifier: str = \"'Date'[DATE_DTE_KEY]\", Number_Of_Intervals: int = 90, Interval: str = 'DAY' ) Pulls the Last X Interval (Ex Last 90 Days) of a specific measure. Args Model (pytabular.Tabular) : Tabular Model to perform query on. Measure (Union[str,pytabular.pytabular.Measure]) : Measure to query. If string, will first check for a measure in the model with that name, otherwise will assume it is a DAX Expression (Ex SUM(FactTable[ColumnValue]) ) and perform that as expression Column_Name (Union[str,None], optional) : Column Name to be outputted in DataFrame. You can provide your own otherwise will take from the Measure Name. Defaults to \"Result\". Date_Column_Identifier (str, optional) : Date column dax identifier. Defaults to \"'Date'[DATE_DTE_KEY]\". Number_Of_Intervals (int, optional) : This is used to plug in the variables for DATESINPERIOD . Defaults to 90. Interval (str, optional) : Sames as Number_Of_Intervals. Used to plug in parameters of DAX function DATESINPERIOD . Defaults to \"DAY\". Possible options are \"DAY\", \"MONTH\", \"QUARTER\", and \"YEAR\" Returns DataFrame : Pandas DataFrame of results.","title":"Examples"},{"location":"Examples/#_1","text":"","title":""},{"location":"Examples/#return_zero_row_tables","text":"source .Return_Zero_Row_Tables( model: pytabular.Tabular ) Returns list of table names of those that are returning isna() Args model (pytabular.Tabular) : Tabular Model Returns List of table names where DAX COUNTROWS('Table Name') is nan or 0.","title":"Return_Zero_Row_Tables"},{"location":"Examples/#table_last_refresh_times","text":"source .Table_Last_Refresh_Times( model: pytabular.Tabular, group_partition: bool = True ) Returns pd.DataFrame of tables with their latest refresh time. Optional 'group_partition' variable, default is True. If False an extra column will be include to have the last refresh time to the grain of the partition Example to add to model model.Create_Table(p.Table_Last_Refresh_Times(model),'RefreshTimes') Args model (pytabular.Tabular) : Tabular Model group_partition (bool, optional) : Whether or not you want the grain of the dataframe to be by table or by partition. Defaults to True. Returns DataFrame : pd dataframe with the RefreshedTime property: https://docs.microsoft.com/en-us/dotnet/api/microsoft.analysisservices.tabular.partition.refreshedtime?view=analysisservices-dotnet#microsoft-analysisservices-tabular-partition-refreshedtime If group_partition == True and the table has multiple partitions, then df.groupby(by[\"tables\"]).max()","title":"Table_Last_Refresh_Times"},{"location":"Examples/#bpa_violations_to_df","text":"source .BPA_Violations_To_DF( model: pytabular.Tabular, te2: str, bpa: str ) Runs BPA Analyzer from TE2 and outputs result into a DF. Args model (pytabular.Tabular) : Tabular Model Class te2 (str) : TE2 Exe File Path (Can use TE2().EXE_path) bpa (str) : BPA File Location (Can use BPA().Location) Returns DataFrame : Super simple right now. Just splits into two columns.. The object in violation and the rule.","title":"BPA_Violations_To_DF"},{"location":"Examples/#last_x_interval","text":"source .Last_X_Interval( Model: pytabular.Tabular, Measure: Union[str, PyMeasure], Column_Name: Union[str, None] = None, Date_Column_Identifier: str = \"'Date'[DATE_DTE_KEY]\", Number_Of_Intervals: int = 90, Interval: str = 'DAY' ) Pulls the Last X Interval (Ex Last 90 Days) of a specific measure. Args Model (pytabular.Tabular) : Tabular Model to perform query on. Measure (Union[str,pytabular.pytabular.Measure]) : Measure to query. If string, will first check for a measure in the model with that name, otherwise will assume it is a DAX Expression (Ex SUM(FactTable[ColumnValue]) ) and perform that as expression Column_Name (Union[str,None], optional) : Column Name to be outputted in DataFrame. You can provide your own otherwise will take from the Measure Name. Defaults to \"Result\". Date_Column_Identifier (str, optional) : Date column dax identifier. Defaults to \"'Date'[DATE_DTE_KEY]\". Number_Of_Intervals (int, optional) : This is used to plug in the variables for DATESINPERIOD . Defaults to 90. Interval (str, optional) : Sames as Number_Of_Intervals. Used to plug in parameters of DAX function DATESINPERIOD . Defaults to \"DAY\". Possible options are \"DAY\", \"MONTH\", \"QUARTER\", and \"YEAR\" Returns DataFrame : Pandas DataFrame of results.","title":"Last_X_Interval"},{"location":"Logic%20Utils/","text":"ticks_to_datetime source .ticks_to_datetime( ticks: int ) Converts a C# System DateTime Tick into a Python DateTime Args ticks (int) : C# DateTime Tick Returns datetime : datetime.datetime pandas_datatype_to_tabular_datatype source .pandas_datatype_to_tabular_datatype( df: pd.DataFrame ) WiP takes dataframe columns and gets respective tabular column datatype. ( NumPy Datatypes and Tabular Datatypes ) Args df (pd.DataFrame) : Pandas DataFrame Returns Dict : EX {'col1': , 'col2': , 'col3': } pd_dataframe_to_m_expression source .pd_dataframe_to_m_expression( df: pd.DataFrame ) This will take a pandas dataframe and convert to an m expression For example this DF: col1 col2 0 1 3 1 2 4 | | V Will convert to this expression string: let Source=#table({\"col1\",\"col2\"}, { {\"1\",\"3\"},{\"2\",\"4\"} }) in Source Args df (pd.DataFrame) : Pandas DataFrame Returns str : Currently only returning string values in your tabular model. remove_folder_and_contents source .remove_folder_and_contents( folder_location ) Internal used in tabular_editor.py and best_practice_analyzer.py. Args folder_location (str) : Folder path to remove directory and contents. remove_suffix source .remove_suffix( input_string, suffix ) Adding for >3.9 compatiblity. Stackoverflow Answer Args input_string (str) : input string to remove suffix from suffix (str) : suffix to be removed Returns str : input_str with suffix removed","title":"Logic Utils"},{"location":"Logic%20Utils/#_1","text":"","title":""},{"location":"Logic%20Utils/#ticks_to_datetime","text":"source .ticks_to_datetime( ticks: int ) Converts a C# System DateTime Tick into a Python DateTime Args ticks (int) : C# DateTime Tick Returns datetime : datetime.datetime","title":"ticks_to_datetime"},{"location":"Logic%20Utils/#pandas_datatype_to_tabular_datatype","text":"source .pandas_datatype_to_tabular_datatype( df: pd.DataFrame ) WiP takes dataframe columns and gets respective tabular column datatype. ( NumPy Datatypes and Tabular Datatypes ) Args df (pd.DataFrame) : Pandas DataFrame Returns Dict : EX {'col1': , 'col2': , 'col3': }","title":"pandas_datatype_to_tabular_datatype"},{"location":"Logic%20Utils/#pd_dataframe_to_m_expression","text":"source .pd_dataframe_to_m_expression( df: pd.DataFrame ) This will take a pandas dataframe and convert to an m expression For example this DF: col1 col2 0 1 3 1 2 4 | | V Will convert to this expression string: let Source=#table({\"col1\",\"col2\"}, { {\"1\",\"3\"},{\"2\",\"4\"} }) in Source Args df (pd.DataFrame) : Pandas DataFrame Returns str : Currently only returning string values in your tabular model.","title":"pd_dataframe_to_m_expression"},{"location":"Logic%20Utils/#remove_folder_and_contents","text":"source .remove_folder_and_contents( folder_location ) Internal used in tabular_editor.py and best_practice_analyzer.py. Args folder_location (str) : Folder path to remove directory and contents.","title":"remove_folder_and_contents"},{"location":"Logic%20Utils/#remove_suffix","text":"source .remove_suffix( input_string, suffix ) Adding for >3.9 compatiblity. Stackoverflow Answer Args input_string (str) : input string to remove suffix from suffix (str) : suffix to be removed Returns str : input_str with suffix removed","title":"remove_suffix"},{"location":"Partition/","text":"PyPartition source PyPartition( object, table ) Wrapper for Microsoft.AnalysisServices.Partition . With a few other bells and whistles added to it. WIP Args Table : Parent Table to the Column Methods: .Last_Refresh source .Last_Refresh() Queries RefreshedTime attribute in the partition and converts from C# Ticks to Python datetime Returns datetime : Last Refreshed time of Partition in datetime format .Refresh source .Refresh( *args, **kwargs ) Same method from Model Refresh, you can pass through any extra parameters. For example: Tabular().Tables['Table Name'].Partitions[0].Refresh(Tracing = True) Returns DataFrame : Returns pandas dataframe with some refresh details PyPartitions source PyPartitions( objects )","title":"Partition"},{"location":"Partition/#_1","text":"","title":""},{"location":"Partition/#pypartition","text":"source PyPartition( object, table ) Wrapper for Microsoft.AnalysisServices.Partition . With a few other bells and whistles added to it. WIP Args Table : Parent Table to the Column Methods:","title":"PyPartition"},{"location":"Partition/#last_refresh","text":"source .Last_Refresh() Queries RefreshedTime attribute in the partition and converts from C# Ticks to Python datetime Returns datetime : Last Refreshed time of Partition in datetime format","title":".Last_Refresh"},{"location":"Partition/#refresh","text":"source .Refresh( *args, **kwargs ) Same method from Model Refresh, you can pass through any extra parameters. For example: Tabular().Tables['Table Name'].Partitions[0].Refresh(Tracing = True) Returns DataFrame : Returns pandas dataframe with some refresh details","title":".Refresh"},{"location":"Partition/#pypartitions","text":"source PyPartitions( objects )","title":"PyPartitions"},{"location":"Queries/","text":"Connection source Connection( Server, Effective_User = None ) Subclass for Adomdclient . With some extra items on top. Right now designed for internal use. For example, Query method in the Tabular class is just a wrapper for this class' Query method... So use that instead. Args AdomdConnection ( type ) : description Methods: .Query source .Query( Query_Str: str ) Executes Query on Model and Returns Results in Pandas DataFrame Args Query_Str (str) : Dax Query. Note, needs full syntax (ex: EVALUATE). See (DAX Queries)[https://docs.microsoft.com/en-us/dax/dax-queries]. Will check if query string is a file. If it is, then it will perform a query on whatever is read from the file. It is also possible to query DMV. For example. Query(\"select * from $SYSTEM.DISCOVER_TRACE_EVENT_CATEGORIES\"). See (DMVs)[https://docs.microsoft.com/en-us/analysis-services/instances/use-dynamic-management-views-dmvs-to-monitor-analysis-services?view=asallproducts-allversions] Returns DataFrame : Returns dataframe with results","title":"Queries"},{"location":"Queries/#_1","text":"","title":""},{"location":"Queries/#connection","text":"source Connection( Server, Effective_User = None ) Subclass for Adomdclient . With some extra items on top. Right now designed for internal use. For example, Query method in the Tabular class is just a wrapper for this class' Query method... So use that instead. Args AdomdConnection ( type ) : description Methods:","title":"Connection"},{"location":"Queries/#query","text":"source .Query( Query_Str: str ) Executes Query on Model and Returns Results in Pandas DataFrame Args Query_Str (str) : Dax Query. Note, needs full syntax (ex: EVALUATE). See (DAX Queries)[https://docs.microsoft.com/en-us/dax/dax-queries]. Will check if query string is a file. If it is, then it will perform a query on whatever is read from the file. It is also possible to query DMV. For example. Query(\"select * from $SYSTEM.DISCOVER_TRACE_EVENT_CATEGORIES\"). See (DMVs)[https://docs.microsoft.com/en-us/analysis-services/instances/use-dynamic-management-views-dmvs-to-monitor-analysis-services?view=asallproducts-allversions] Returns DataFrame : Returns dataframe with results","title":".Query"},{"location":"Refreshes/","text":"PyRefresh source PyRefresh( model, object: Union[str, PyTable, PyPartition, Dict[str, Any]], trace: Base_Trace = Refresh_Trace, refresh_checks: Refresh_Check_Collection = Refresh_Check_Collection(), default_row_count_check: bool = True, refresh_type: RefreshType = RefreshType.Full ) Methods: .Run source .Run() Refresh_Check source Refresh_Check( name, function, assertion = None ) Methods: .name source .name() Get your custom name of refresh check. .function source .function() Get the function that is used to run a pre and post check. .pre source .pre() Get the pre value that is the result from the pre refresh check. .post source .post() Get the post value that is the result from the post refresh check. .assertion source .assertion() Get the assertion that is the result from the post refresh check. .Pre_Check source .Pre_Check() .Post_Check source .Post_Check() .Assertion source .Assertion() Refresh_Check_Collection source Refresh_Check_Collection( refresh_checks: Refresh_Check = [] ) Methods: .add_refresh_check source .add_refresh_check( refresh_check: Refresh_Check ) .remove_refresh_check source .remove_refresh_check( refresh_check: Refresh_Check ) .clear_refresh_checks source .clear_refresh_checks()","title":"Refreshes"},{"location":"Refreshes/#_1","text":"","title":""},{"location":"Refreshes/#pyrefresh","text":"source PyRefresh( model, object: Union[str, PyTable, PyPartition, Dict[str, Any]], trace: Base_Trace = Refresh_Trace, refresh_checks: Refresh_Check_Collection = Refresh_Check_Collection(), default_row_count_check: bool = True, refresh_type: RefreshType = RefreshType.Full ) Methods:","title":"PyRefresh"},{"location":"Refreshes/#run","text":"source .Run()","title":".Run"},{"location":"Refreshes/#refresh_check","text":"source Refresh_Check( name, function, assertion = None ) Methods:","title":"Refresh_Check"},{"location":"Refreshes/#name","text":"source .name() Get your custom name of refresh check.","title":".name"},{"location":"Refreshes/#function","text":"source .function() Get the function that is used to run a pre and post check.","title":".function"},{"location":"Refreshes/#pre","text":"source .pre() Get the pre value that is the result from the pre refresh check.","title":".pre"},{"location":"Refreshes/#post","text":"source .post() Get the post value that is the result from the post refresh check.","title":".post"},{"location":"Refreshes/#assertion","text":"source .assertion() Get the assertion that is the result from the post refresh check.","title":".assertion"},{"location":"Refreshes/#pre_check","text":"source .Pre_Check()","title":".Pre_Check"},{"location":"Refreshes/#post_check","text":"source .Post_Check()","title":".Post_Check"},{"location":"Refreshes/#assertion_1","text":"source .Assertion()","title":".Assertion"},{"location":"Refreshes/#refresh_check_collection","text":"source Refresh_Check_Collection( refresh_checks: Refresh_Check = [] ) Methods:","title":"Refresh_Check_Collection"},{"location":"Refreshes/#add_refresh_check","text":"source .add_refresh_check( refresh_check: Refresh_Check )","title":".add_refresh_check"},{"location":"Refreshes/#remove_refresh_check","text":"source .remove_refresh_check( refresh_check: Refresh_Check )","title":".remove_refresh_check"},{"location":"Refreshes/#clear_refresh_checks","text":"source .clear_refresh_checks()","title":".clear_refresh_checks"},{"location":"Table/","text":"PyTable source PyTable( object, model ) Wrapper for Microsoft.AnalysisServices.Tabular.Table . With a few other bells and whistles added to it. You can use the table to access the nested Columns and Partitions. WIP Attributes Model : Reference to Tabular class Partitions : Reference to Table Partitions Columns : Reference to Table Columns Methods: .Row_Count source .Row_Count() Method to return count of rows. Simple Dax Query: EVALUATE {COUNTROWS('Table Name')} Returns int : Number of rows using COUNTROWS . .Refresh source .Refresh( *args, **kwargs ) Same method from Model Refresh, you can pass through any extra parameters. For example: Tabular().Tables['Table Name'].Refresh(Tracing = True) Returns DataFrame : Returns pandas dataframe with some refresh details .Last_Refresh source .Last_Refresh() Will query each partition for the last refresh time then select the max Returns datetime : Last refresh time in datetime format .Related source .Related() PyTables source PyTables( objects ) Iterator to handle tables. Accessible via Tables attribute in Tabular class. Args PyTable : PyTable class Methods: .Refresh source .Refresh( *args, **kwargs )","title":"Table"},{"location":"Table/#_1","text":"","title":""},{"location":"Table/#pytable","text":"source PyTable( object, model ) Wrapper for Microsoft.AnalysisServices.Tabular.Table . With a few other bells and whistles added to it. You can use the table to access the nested Columns and Partitions. WIP Attributes Model : Reference to Tabular class Partitions : Reference to Table Partitions Columns : Reference to Table Columns Methods:","title":"PyTable"},{"location":"Table/#row_count","text":"source .Row_Count() Method to return count of rows. Simple Dax Query: EVALUATE {COUNTROWS('Table Name')} Returns int : Number of rows using COUNTROWS .","title":".Row_Count"},{"location":"Table/#refresh","text":"source .Refresh( *args, **kwargs ) Same method from Model Refresh, you can pass through any extra parameters. For example: Tabular().Tables['Table Name'].Refresh(Tracing = True) Returns DataFrame : Returns pandas dataframe with some refresh details","title":".Refresh"},{"location":"Table/#last_refresh","text":"source .Last_Refresh() Will query each partition for the last refresh time then select the max Returns datetime : Last refresh time in datetime format","title":".Last_Refresh"},{"location":"Table/#related","text":"source .Related()","title":".Related"},{"location":"Table/#pytables","text":"source PyTables( objects ) Iterator to handle tables. Accessible via Tables attribute in Tabular class. Args PyTable : PyTable class Methods:","title":"PyTables"},{"location":"Table/#refresh_1","text":"source .Refresh( *args, **kwargs )","title":".Refresh"},{"location":"Tabular%20Editor%202/","text":"Tabular_Editor source Tabular_Editor( EXE_File_Path: str = 'Default' ) Setting Tabular_Editor Class for future work. Download_Tabular_Editor source .Download_Tabular_Editor( Download_Location: str = 'https: //github.com/TabularEditor/TabularEditor/releases/download/2.16.7/TabularEditor.Portable.zip', Folder: str = 'Tabular_Editor_2', Auto_Remove = True ) Runs a request.get() to retrieve the zip file from web. Will unzip response and store in directory. Will also register the removal of the new directory and files when exiting program. Args Download_Location (str, optional) : File path for zip of Tabular Editor 2. Defaults to [Tabular Editor 2 Github Zip Location]'https://github.com/TabularEditor/TabularEditor/releases/download/2.16.7/TabularEditor.Portable.zip'. Folder (str, optional) : New Folder Location. Defaults to 'Tabular_Editor_2'. Auto_Remove (bool, optional) : Boolean to determine auto removal of files once script exits. Defaults to True. Returns str : File path of TabularEditor.exe","title":"Tabular Editor"},{"location":"Tabular%20Editor%202/#_1","text":"","title":""},{"location":"Tabular%20Editor%202/#tabular_editor","text":"source Tabular_Editor( EXE_File_Path: str = 'Default' ) Setting Tabular_Editor Class for future work.","title":"Tabular_Editor"},{"location":"Tabular%20Editor%202/#download_tabular_editor","text":"source .Download_Tabular_Editor( Download_Location: str = 'https: //github.com/TabularEditor/TabularEditor/releases/download/2.16.7/TabularEditor.Portable.zip', Folder: str = 'Tabular_Editor_2', Auto_Remove = True ) Runs a request.get() to retrieve the zip file from web. Will unzip response and store in directory. Will also register the removal of the new directory and files when exiting program. Args Download_Location (str, optional) : File path for zip of Tabular Editor 2. Defaults to [Tabular Editor 2 Github Zip Location]'https://github.com/TabularEditor/TabularEditor/releases/download/2.16.7/TabularEditor.Portable.zip'. Folder (str, optional) : New Folder Location. Defaults to 'Tabular_Editor_2'. Auto_Remove (bool, optional) : Boolean to determine auto removal of files once script exits. Defaults to True. Returns str : File path of TabularEditor.exe","title":"Download_Tabular_Editor"},{"location":"Tabular/","text":"Tabular source Tabular( CONNECTION_STR: str ) Tabular Class to perform operations: Microsoft.AnalysisServices.Tabular . You can use this class as your main way to interact with your model. Args CONNECTION_STR (str) : Valid Connection String for connecting to a Tabular Model. Attributes Server (Server) : See Server MS Docs . Catalog (str) : Name of Database. See Catalog MS Docs . Model (Model) : See Model MS Docs . AdomdConnection (AdomdConnection) : For querying. See AdomdConnection MS Docs . Connection made from parts of the originally provided connection string. Tables (PyTables[PyTable]) : Wrappers for Table MS Docs . So you have the full capabilities of what the MS Docs offer and a few others. Like Tabular().Tables['Table Name'].Row_Count() . Or you can find a table via Tabular().Tables[0] or Tabular().Tables['Table Name'] Columns (List[Column]) : Easy access list of columns from model. See Column MS Docs . Partitions (List[Partition]) : Easy access list of partitions from model. See Partition MS Docs . Measures (List[Measure]) : Easy access list of measures from model. See Measure MS Docs . Methods: .Reload_Model_Info source .Reload_Model_Info() Runs on init iterates through details, can be called after any model changes. Called in SaveChanges() Returns bool : True if successful .Is_Process source .Is_Process() Run method to check if Processing is occurring. Will query DMV $SYSTEM.DISCOVER_JOBS to see if any processing is happening. Returns bool : True if DMV shows Process, False if not. .Disconnect source .Disconnect() Disconnects from Model Returns bool : True if successful .Refresh source .Refresh( *args, **kwargs ) PyRefresh Class to handle refreshes of model. Args model (Tabular) : Main Tabular Class object (Union[str, PyTable, PyPartition, Dict[str, Any]]) : Designed to handle a few different ways of selecting a refresh. Can be a string of 'Table Name' or dict of {'Table Name': 'Partition Name'} or even some combination with the actual PyTable and PyPartition classes. trace (Base_Trace, optional) : Set to None if no Tracing is desired, otherwise you can use default trace or create your own. Defaults to Refresh_Trace. refresh_checks (Refresh_Check_Collection, optional) : Add your Refresh_Check 's into a Refresh_Check_Collection . Defaults to Refresh_Check_Collection(). default_row_count_check (bool, optional) : Quick built in check will fail the refresh if post check row count is zero. Defaults to True. refresh_type (RefreshType, optional) : Input RefreshType desired. Defaults to RefreshType.Full. Returns pd.DataFrame .Update source .Update( UpdateOptions: UpdateOptions = UpdateOptions.ExpandFull ) Update Model Args UpdateOptions (UpdateOptions, optional) : See above MS Doc link. Defaults to UpdateOptions.ExpandFull. Returns None : Placeholder to eventually change. .SaveChanges source .SaveChanges() .Backup_Table source .Backup_Table( table_str: str ) USE WITH CAUTION, EXPERIMENTAL. Backs up table in memory, brings with it measures, columns, hierarchies, relationships, roles, etc. It will add suffix '_backup' to all objects. Refresh is performed from source during backup. Args table_str (str, optional) : Name of Table. Returns bool : Returns True if Successful, else will return error. .Revert_Table source .Revert_Table( table_str: str ) USE WITH CAUTION, EXPERIMENTAL. This is used in conjunction with Backup_Table(). It will take the 'TableName_backup' and replace with the original. Example scenario -> 1. model.Backup_Table('TableName') 2. perform any proposed changes in original 'TableName' 3. validate changes in 'TableName' 4. if unsuccessful run model.Revert_Table('TableName') Args table_str (str) : Name of table. Returns bool : Returns True if Successful, else will return error. .Query source .Query( Query_Str: str, Effective_User: str = None ) Executes Query on Model and Returns Results in Pandas DataFrame Args Query_Str (str) : Dax Query. Note, needs full syntax (ex: EVALUATE). See (DAX Queries)[https://docs.microsoft.com/en-us/dax/dax-queries]. Effective_User (str) : User you wish to query as. Will check if query string is a file. If it is, then it will perform a query on whatever is read from the file. It is also possible to query DMV. For example. Query(\"select * from $SYSTEM.DISCOVER_TRACE_EVENT_CATEGORIES\"). See (DMVs)[https://docs.microsoft.com/en-us/analysis-services/instances/use-dynamic-management-views-dmvs-to-monitor-analysis-services?view=asallproducts-allversions] Returns DataFrame : Returns dataframe with results .Query_Every_Column source .Query_Every_Column( query_function: str = 'COUNTROWS(VALUES(_))' ) This will dynamically create a query to pull all columns from the model and run the query function. It will replace the _ with the column to run. Args query_function (str, optional) : Dax query is dynamically building a query with the UNION & ROW DAX Functions. Returns DataFrame : Returns dataframe with results. .Query_Every_Table source .Query_Every_Table( query_function: str = 'COUNTROWS(_)' ) This will dynamically create a query to pull all tables from the model and run the query function. It will replace the _ with the table to run. Args query_function (str, optional) : Dax query is dynamically building a query with the UNION & ROW DAX Functions. Defaults to 'COUNTROWS(_)'. Returns DataFrame : Returns dataframe with results .Analyze_BPA source .Analyze_BPA( Tabular_Editor_Exe: str, Best_Practice_Analyzer: str ) Takes your Tabular Model and performs TE2s BPA. Runs through Command line. Tabular Editor BPA Tabular Editor Command Line Options Args Tabular_Editor_Exe (str) : TE2 Exe File path. Feel free to use class TE2().EXE_Path or provide your own. Best_Practice_Analyzer (str) : BPA json file path. Feel free to use class BPA().Location or provide your own. Defualts to https://raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json Returns Assuming no failure, will return list of BPA violations. Else will return error from command line. .Create_Table source .Create_Table( df: pd.DataFrame, table_name: str ) Creates tables from pd.DataFrame as an M-Partition. So will convert the dataframe to M-Partition logic via the M query table constructor. Runs refresh and will update model. Args df (pd.DataFrame) : DataFrame to add to model table_name (str) : description Returns bool : True if successful","title":"Tabular"},{"location":"Tabular/#_1","text":"","title":""},{"location":"Tabular/#tabular","text":"source Tabular( CONNECTION_STR: str ) Tabular Class to perform operations: Microsoft.AnalysisServices.Tabular . You can use this class as your main way to interact with your model. Args CONNECTION_STR (str) : Valid Connection String for connecting to a Tabular Model. Attributes Server (Server) : See Server MS Docs . Catalog (str) : Name of Database. See Catalog MS Docs . Model (Model) : See Model MS Docs . AdomdConnection (AdomdConnection) : For querying. See AdomdConnection MS Docs . Connection made from parts of the originally provided connection string. Tables (PyTables[PyTable]) : Wrappers for Table MS Docs . So you have the full capabilities of what the MS Docs offer and a few others. Like Tabular().Tables['Table Name'].Row_Count() . Or you can find a table via Tabular().Tables[0] or Tabular().Tables['Table Name'] Columns (List[Column]) : Easy access list of columns from model. See Column MS Docs . Partitions (List[Partition]) : Easy access list of partitions from model. See Partition MS Docs . Measures (List[Measure]) : Easy access list of measures from model. See Measure MS Docs . Methods:","title":"Tabular"},{"location":"Tabular/#reload_model_info","text":"source .Reload_Model_Info() Runs on init iterates through details, can be called after any model changes. Called in SaveChanges() Returns bool : True if successful","title":".Reload_Model_Info"},{"location":"Tabular/#is_process","text":"source .Is_Process() Run method to check if Processing is occurring. Will query DMV $SYSTEM.DISCOVER_JOBS to see if any processing is happening. Returns bool : True if DMV shows Process, False if not.","title":".Is_Process"},{"location":"Tabular/#disconnect","text":"source .Disconnect() Disconnects from Model Returns bool : True if successful","title":".Disconnect"},{"location":"Tabular/#refresh","text":"source .Refresh( *args, **kwargs ) PyRefresh Class to handle refreshes of model. Args model (Tabular) : Main Tabular Class object (Union[str, PyTable, PyPartition, Dict[str, Any]]) : Designed to handle a few different ways of selecting a refresh. Can be a string of 'Table Name' or dict of {'Table Name': 'Partition Name'} or even some combination with the actual PyTable and PyPartition classes. trace (Base_Trace, optional) : Set to None if no Tracing is desired, otherwise you can use default trace or create your own. Defaults to Refresh_Trace. refresh_checks (Refresh_Check_Collection, optional) : Add your Refresh_Check 's into a Refresh_Check_Collection . Defaults to Refresh_Check_Collection(). default_row_count_check (bool, optional) : Quick built in check will fail the refresh if post check row count is zero. Defaults to True. refresh_type (RefreshType, optional) : Input RefreshType desired. Defaults to RefreshType.Full. Returns pd.DataFrame","title":".Refresh"},{"location":"Tabular/#update","text":"source .Update( UpdateOptions: UpdateOptions = UpdateOptions.ExpandFull ) Update Model Args UpdateOptions (UpdateOptions, optional) : See above MS Doc link. Defaults to UpdateOptions.ExpandFull. Returns None : Placeholder to eventually change.","title":".Update"},{"location":"Tabular/#savechanges","text":"source .SaveChanges()","title":".SaveChanges"},{"location":"Tabular/#backup_table","text":"source .Backup_Table( table_str: str ) USE WITH CAUTION, EXPERIMENTAL. Backs up table in memory, brings with it measures, columns, hierarchies, relationships, roles, etc. It will add suffix '_backup' to all objects. Refresh is performed from source during backup. Args table_str (str, optional) : Name of Table. Returns bool : Returns True if Successful, else will return error.","title":".Backup_Table"},{"location":"Tabular/#revert_table","text":"source .Revert_Table( table_str: str ) USE WITH CAUTION, EXPERIMENTAL. This is used in conjunction with Backup_Table(). It will take the 'TableName_backup' and replace with the original. Example scenario -> 1. model.Backup_Table('TableName') 2. perform any proposed changes in original 'TableName' 3. validate changes in 'TableName' 4. if unsuccessful run model.Revert_Table('TableName') Args table_str (str) : Name of table. Returns bool : Returns True if Successful, else will return error.","title":".Revert_Table"},{"location":"Tabular/#query","text":"source .Query( Query_Str: str, Effective_User: str = None ) Executes Query on Model and Returns Results in Pandas DataFrame Args Query_Str (str) : Dax Query. Note, needs full syntax (ex: EVALUATE). See (DAX Queries)[https://docs.microsoft.com/en-us/dax/dax-queries]. Effective_User (str) : User you wish to query as. Will check if query string is a file. If it is, then it will perform a query on whatever is read from the file. It is also possible to query DMV. For example. Query(\"select * from $SYSTEM.DISCOVER_TRACE_EVENT_CATEGORIES\"). See (DMVs)[https://docs.microsoft.com/en-us/analysis-services/instances/use-dynamic-management-views-dmvs-to-monitor-analysis-services?view=asallproducts-allversions] Returns DataFrame : Returns dataframe with results","title":".Query"},{"location":"Tabular/#query_every_column","text":"source .Query_Every_Column( query_function: str = 'COUNTROWS(VALUES(_))' ) This will dynamically create a query to pull all columns from the model and run the query function. It will replace the _ with the column to run. Args query_function (str, optional) : Dax query is dynamically building a query with the UNION & ROW DAX Functions. Returns DataFrame : Returns dataframe with results.","title":".Query_Every_Column"},{"location":"Tabular/#query_every_table","text":"source .Query_Every_Table( query_function: str = 'COUNTROWS(_)' ) This will dynamically create a query to pull all tables from the model and run the query function. It will replace the _ with the table to run. Args query_function (str, optional) : Dax query is dynamically building a query with the UNION & ROW DAX Functions. Defaults to 'COUNTROWS(_)'. Returns DataFrame : Returns dataframe with results","title":".Query_Every_Table"},{"location":"Tabular/#analyze_bpa","text":"source .Analyze_BPA( Tabular_Editor_Exe: str, Best_Practice_Analyzer: str ) Takes your Tabular Model and performs TE2s BPA. Runs through Command line. Tabular Editor BPA Tabular Editor Command Line Options Args Tabular_Editor_Exe (str) : TE2 Exe File path. Feel free to use class TE2().EXE_Path or provide your own. Best_Practice_Analyzer (str) : BPA json file path. Feel free to use class BPA().Location or provide your own. Defualts to https://raw.githubusercontent.com/microsoft/Analysis-Services/master/BestPracticeRules/BPARules.json Returns Assuming no failure, will return list of BPA violations. Else will return error from command line.","title":".Analyze_BPA"},{"location":"Tabular/#create_table","text":"source .Create_Table( df: pd.DataFrame, table_name: str ) Creates tables from pd.DataFrame as an M-Partition. So will convert the dataframe to M-Partition logic via the M query table constructor. Runs refresh and will update model. Args df (pd.DataFrame) : DataFrame to add to model table_name (str) : description Returns bool : True if successful","title":".Create_Table"},{"location":"Traces/","text":"Base_Trace source Base_Trace( Tabular_Class, Trace_Events: List[TraceEvent], Trace_Event_Columns: List[TraceColumn], Handler: Callable ) Generates Trace to be run on Server. This is the base class to customize the type of Trace you are looking for. Server Traces Args Tabular_Class (Tabular) : Tabular Class. Trace_Events (List[TraceEvent]) : List of Trace Events. Trace_Event_Columns (List[TraceColumn]) : List of Trace Event Columns. Handler (Callable) : Function to call when Trace returns response. TraceEventClass TraceEventColumn Input needs to be two arguments. One is source (Which is currently None... Need to investigate why). Second is TraceEventArgs Methods: .Build source .Build() Run on initialization. This will take the inputed arguments for the class and attempt to build the Trace. Returns bool : True if successful .Arguments source .Arguments( Trace_Events: List[TraceEvent], Trace_Event_Columns: List[TraceColumn], Handler: Callable ) .Add source .Add() Runs on initialization. Adds built Trace to the Server. Returns int : Return int of placement in Server.Traces.get_Item(int) .Update source .Update() Runs on initialization. Syncs with Server. Returns None : Returns None. Unless unsuccessful then it will return the error from Server. .Start source .Start() Call when you want to start the Trace Returns None : Returns None. Unless unsuccessful then it will return the error from Server. .Stop source .Stop() Call when you want to stop the Trace Returns None : Returns None. Unless unsuccessful then it will return the error from Server. .Drop source .Drop() Call when you want to drop the Trace Returns None : Returns None. Unless unsuccessful, then it will return the error from Server. Refresh_Trace source Refresh_Trace( Tabular_Class, Trace_Events: List[TraceEvent] = [TraceEventClass.ProgressReportBegin, TraceEventClass.ProgressReportCurrent, TraceEventClass.ProgressReportEnd, TraceEventClass.ProgressReportError], Trace_Event_Columns: List[TraceColumn] = [TraceColumn.EventSubclass, TraceColumn.CurrentTime, TraceColumn.ObjectName, TraceColumn.ObjectPath, TraceColumn.DatabaseName, TraceColumn.SessionID, TraceColumn.TextData, TraceColumn.EventClass, TraceColumn.ProgressTotal], Handler: Callable = _refresh_handler ) Subclass of Base_Trace. For built-in Refresh Tracing. Args Base_Trace ( type ) : description","title":"Trace"},{"location":"Traces/#_1","text":"","title":""},{"location":"Traces/#base_trace","text":"source Base_Trace( Tabular_Class, Trace_Events: List[TraceEvent], Trace_Event_Columns: List[TraceColumn], Handler: Callable ) Generates Trace to be run on Server. This is the base class to customize the type of Trace you are looking for. Server Traces Args Tabular_Class (Tabular) : Tabular Class. Trace_Events (List[TraceEvent]) : List of Trace Events. Trace_Event_Columns (List[TraceColumn]) : List of Trace Event Columns. Handler (Callable) : Function to call when Trace returns response. TraceEventClass TraceEventColumn Input needs to be two arguments. One is source (Which is currently None... Need to investigate why). Second is TraceEventArgs Methods:","title":"Base_Trace"},{"location":"Traces/#build","text":"source .Build() Run on initialization. This will take the inputed arguments for the class and attempt to build the Trace. Returns bool : True if successful","title":".Build"},{"location":"Traces/#arguments","text":"source .Arguments( Trace_Events: List[TraceEvent], Trace_Event_Columns: List[TraceColumn], Handler: Callable )","title":".Arguments"},{"location":"Traces/#add","text":"source .Add() Runs on initialization. Adds built Trace to the Server. Returns int : Return int of placement in Server.Traces.get_Item(int)","title":".Add"},{"location":"Traces/#update","text":"source .Update() Runs on initialization. Syncs with Server. Returns None : Returns None. Unless unsuccessful then it will return the error from Server.","title":".Update"},{"location":"Traces/#start","text":"source .Start() Call when you want to start the Trace Returns None : Returns None. Unless unsuccessful then it will return the error from Server.","title":".Start"},{"location":"Traces/#stop","text":"source .Stop() Call when you want to stop the Trace Returns None : Returns None. Unless unsuccessful then it will return the error from Server.","title":".Stop"},{"location":"Traces/#drop","text":"source .Drop() Call when you want to drop the Trace Returns None : Returns None. Unless unsuccessful, then it will return the error from Server.","title":".Drop"},{"location":"Traces/#refresh_trace","text":"source Refresh_Trace( Tabular_Class, Trace_Events: List[TraceEvent] = [TraceEventClass.ProgressReportBegin, TraceEventClass.ProgressReportCurrent, TraceEventClass.ProgressReportEnd, TraceEventClass.ProgressReportError], Trace_Event_Columns: List[TraceColumn] = [TraceColumn.EventSubclass, TraceColumn.CurrentTime, TraceColumn.ObjectName, TraceColumn.ObjectPath, TraceColumn.DatabaseName, TraceColumn.SessionID, TraceColumn.TextData, TraceColumn.EventClass, TraceColumn.ProgressTotal], Handler: Callable = _refresh_handler ) Subclass of Base_Trace. For built-in Refresh Tracing. Args Base_Trace ( type ) : description","title":"Refresh_Trace"},{"location":"contributing/","text":"Contributing Guidelines Work will be distributed under MIT license Pull request into main will run a flake8 test. flake8 will need to pass before pull request will be accepted Updates of any kind are welcome! Even just letting me know of the issues. Or updating doc strings Limit any external modules, see pyproject.toml for dependencies Goal of project is to help connect the python world and the tabular model world for some easier programmatic execution on models. Docstrings follow google docstring format See actions, once main updated, mkgendocs is used to auto create documentation","title":"Contributing Guidelines"},{"location":"contributing/#contributing-guidelines","text":"Work will be distributed under MIT license Pull request into main will run a flake8 test. flake8 will need to pass before pull request will be accepted Updates of any kind are welcome! Even just letting me know of the issues. Or updating doc strings Limit any external modules, see pyproject.toml for dependencies Goal of project is to help connect the python world and the tabular model world for some easier programmatic execution on models. Docstrings follow google docstring format See actions, once main updated, mkgendocs is used to auto create documentation","title":"Contributing Guidelines"}]}